{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600360854636",
   "display_name": "Python 3.8.3 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Chapter 1: Introducing DataFrames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "homelessness= pd.read_csv('../datasets/homelessness.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region       state  individuals  family_members  state_pop\n0  East South Central     Alabama       2570.0           864.0    4887681\n1             Pacific      Alaska       1434.0           582.0     735139\n2            Mountain     Arizona       7259.0          2606.0    7158024\n3  West South Central    Arkansas       2280.0           432.0    3009733\n4             Pacific  California     109008.0         20964.0   39461588\n"
    }
   ],
   "source": [
    "# Print the head of the homelessness data\n",
    "print(homelessness.head())"
   ]
  },
  {
   "source": [
    "* values: A two-dimensional NumPy array of values.\n",
    "* columns: An index of columns: the column names.\n",
    "* index: An index for the rows: either row numbers or row names."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['East South Central' 'Alabama' 2570.0 864.0 4887681]\n ['Pacific' 'Alaska' 1434.0 582.0 735139]\n ['Mountain' 'Arizona' 7259.0 2606.0 7158024]\n ['West South Central' 'Arkansas' 2280.0 432.0 3009733]\n ['Pacific' 'California' 109008.0 20964.0 39461588]\n ['Mountain' 'Colorado' 7607.0 3250.0 5691287]\n ['New England' 'Connecticut' 2280.0 1696.0 3571520]\n ['South Atlantic' 'Delaware' 708.0 374.0 965479]\n ['South Atlantic' 'District of Columbia' 3770.0 3134.0 701547]\n ['South Atlantic' 'Florida' 21443.0 9587.0 21244317]\n ['South Atlantic' 'Georgia' 6943.0 2556.0 10511131]\n ['Pacific' 'Hawaii' 4131.0 2399.0 1420593]\n ['Mountain' 'Idaho' 1297.0 715.0 1750536]\n ['East North Central' 'Illinois' 6752.0 3891.0 12723071]\n ['East North Central' 'Indiana' 3776.0 1482.0 6695497]\n ['West North Central' 'Iowa' 1711.0 1038.0 3148618]\n ['West North Central' 'Kansas' 1443.0 773.0 2911359]\n ['East South Central' 'Kentucky' 2735.0 953.0 4461153]\n ['West South Central' 'Louisiana' 2540.0 519.0 4659690]\n ['New England' 'Maine' 1450.0 1066.0 1339057]\n ['South Atlantic' 'Maryland' 4914.0 2230.0 6035802]\n ['New England' 'Massachusetts' 6811.0 13257.0 6882635]\n ['East North Central' 'Michigan' 5209.0 3142.0 9984072]\n ['West North Central' 'Minnesota' 3993.0 3250.0 5606249]\n ['East South Central' 'Mississippi' 1024.0 328.0 2981020]\n ['West North Central' 'Missouri' 3776.0 2107.0 6121623]\n ['Mountain' 'Montana' 983.0 422.0 1060665]\n ['West North Central' 'Nebraska' 1745.0 676.0 1925614]\n ['Mountain' 'Nevada' 7058.0 486.0 3027341]\n ['New England' 'New Hampshire' 835.0 615.0 1353465]\n ['Mid-Atlantic' 'New Jersey' 6048.0 3350.0 8886025]\n ['Mountain' 'New Mexico' 1949.0 602.0 2092741]\n ['Mid-Atlantic' 'New York' 39827.0 52070.0 19530351]\n ['South Atlantic' 'North Carolina' 6451.0 2817.0 10381615]\n ['West North Central' 'North Dakota' 467.0 75.0 758080]\n ['East North Central' 'Ohio' 6929.0 3320.0 11676341]\n ['West South Central' 'Oklahoma' 2823.0 1048.0 3940235]\n ['Pacific' 'Oregon' 11139.0 3337.0 4181886]\n ['Mid-Atlantic' 'Pennsylvania' 8163.0 5349.0 12800922]\n ['New England' 'Rhode Island' 747.0 354.0 1058287]\n ['South Atlantic' 'South Carolina' 3082.0 851.0 5084156]\n ['West North Central' 'South Dakota' 836.0 323.0 878698]\n ['East South Central' 'Tennessee' 6139.0 1744.0 6771631]\n ['West South Central' 'Texas' 19199.0 6111.0 28628666]\n ['Mountain' 'Utah' 1904.0 972.0 3153550]\n ['New England' 'Vermont' 780.0 511.0 624358]\n ['South Atlantic' 'Virginia' 3928.0 2047.0 8501286]\n ['Pacific' 'Washington' 16424.0 5880.0 7523869]\n ['South Atlantic' 'West Virginia' 1021.0 222.0 1804291]\n ['East North Central' 'Wisconsin' 2740.0 2167.0 5807406]\n ['Mountain' 'Wyoming' 434.0 205.0 577601]]\nIndex(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')\nInt64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n            50],\n           dtype='int64')\n"
    }
   ],
   "source": [
    "# Import pandas using the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Print the values of homelessness\n",
    "print(homelessness.values)\n",
    "\n",
    "# Print the column index of homelessness\n",
    "print(homelessness.columns)\n",
    "\n",
    "# Print the row index of homelessness\n",
    "print(homelessness.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region         state  individuals  family_members  state_pop\n50            Mountain       Wyoming        434.0           205.0     577601\n34  West North Central  North Dakota        467.0            75.0     758080\n7       South Atlantic      Delaware        708.0           374.0     965479\n39         New England  Rhode Island        747.0           354.0    1058287\n45         New England       Vermont        780.0           511.0     624358\n"
    }
   ],
   "source": [
    "# Sort homelessness by individual\n",
    "#print(homelessness.columns)\n",
    "homelessness_ind = homelessness.sort_values(\"individuals\")\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_ind.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region          state  individuals  family_members  state_pop\n32        Mid-Atlantic       New York      39827.0         52070.0   19530351\n4              Pacific     California     109008.0         20964.0   39461588\n21         New England  Massachusetts       6811.0         13257.0    6882635\n9       South Atlantic        Florida      21443.0          9587.0   21244317\n43  West South Central          Texas      19199.0          6111.0   28628666\n"
    }
   ],
   "source": [
    "# Sort homelessness by descending family members\n",
    "homelessness_fam = homelessness.sort_values(\"family_members\",ascending=False)\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region      state  individuals  family_members  state_pop\n13  East North Central   Illinois       6752.0          3891.0   12723071\n35  East North Central       Ohio       6929.0          3320.0   11676341\n22  East North Central   Michigan       5209.0          3142.0    9984072\n49  East North Central  Wisconsin       2740.0          2167.0    5807406\n14  East North Central    Indiana       3776.0          1482.0    6695497\n"
    }
   ],
   "source": [
    "# Sort homelessness by region, then descending family members\n",
    "homelessness_reg_fam = homelessness.sort_values([\"region\",\"family_members\"],ascending=(True,False))\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0      2570.0\n1      1434.0\n2      7259.0\n3      2280.0\n4    109008.0\nName: individuals, dtype: float64\n"
    }
   ],
   "source": [
    "# Select the individuals column\n",
    "individuals = homelessness[\"individuals\"]\n",
    "\n",
    "# Print the head of the result\n",
    "print(individuals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "state  family_members\n0     Alabama           864.0\n1      Alaska           582.0\n2     Arizona          2606.0\n3    Arkansas           432.0\n4  California         20964.0\n"
    }
   ],
   "source": [
    "# Select the state and family_members columns\n",
    "state_fam = homelessness[[\"state\",\"family_members\"]]\n",
    "\n",
    "# Print the head of the result\n",
    "print(state_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "individuals       state\n0       2570.0     Alabama\n1       1434.0      Alaska\n2       7259.0     Arizona\n3       2280.0    Arkansas\n4     109008.0  California\n"
    }
   ],
   "source": [
    "# Select only the individuals and state columns, in that order\n",
    "ind_state = homelessness[[\"individuals\",\"state\"]]\n",
    "\n",
    "# Print the head of the result\n",
    "print(ind_state.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region       state  individuals  family_members  state_pop\n4              Pacific  California     109008.0         20964.0   39461588\n9       South Atlantic     Florida      21443.0          9587.0   21244317\n32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n37             Pacific      Oregon      11139.0          3337.0    4181886\n43  West South Central       Texas      19199.0          6111.0   28628666\n47             Pacific  Washington      16424.0          5880.0    7523869\n"
    }
   ],
   "source": [
    "# Filter for rows where individuals is greater than 10000\n",
    "ind_gt_10k = homelessness[homelessness[\"individuals\"]>10000]\n",
    "\n",
    "# See the result\n",
    "print(ind_gt_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region       state  individuals  family_members  state_pop\n2   Mountain     Arizona       7259.0          2606.0    7158024\n5   Mountain    Colorado       7607.0          3250.0    5691287\n12  Mountain       Idaho       1297.0           715.0    1750536\n26  Mountain     Montana        983.0           422.0    1060665\n28  Mountain      Nevada       7058.0           486.0    3027341\n31  Mountain  New Mexico       1949.0           602.0    2092741\n44  Mountain        Utah       1904.0           972.0    3153550\n50  Mountain     Wyoming        434.0           205.0     577601\n"
    }
   ],
   "source": [
    "# Filter for rows where region is Mountain\n",
    "mountain_reg = homelessness[homelessness[\"region\"]==\"Mountain\"]\n",
    "\n",
    "# See the result\n",
    "print(mountain_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region   state  individuals  family_members  state_pop\n1  Pacific  Alaska       1434.0           582.0     735139\n"
    }
   ],
   "source": [
    "# Filter for rows where family_members is less than 1000 \n",
    "# and region is Pacific\n",
    "fam_lt_1k_pac = homelessness[(homelessness[\"family_members\"]<1000) & (homelessness[\"region\"]==\"Pacific\")]\n",
    "\n",
    "# See the result\n",
    "print(fam_lt_1k_pac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region                 state  individuals  family_members  \\\n7   South Atlantic              Delaware        708.0           374.0   \n8   South Atlantic  District of Columbia       3770.0          3134.0   \n9   South Atlantic               Florida      21443.0          9587.0   \n10  South Atlantic               Georgia       6943.0          2556.0   \n20  South Atlantic              Maryland       4914.0          2230.0   \n30    Mid-Atlantic            New Jersey       6048.0          3350.0   \n32    Mid-Atlantic              New York      39827.0         52070.0   \n33  South Atlantic        North Carolina       6451.0          2817.0   \n38    Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n40  South Atlantic        South Carolina       3082.0           851.0   \n46  South Atlantic              Virginia       3928.0          2047.0   \n48  South Atlantic         West Virginia       1021.0           222.0   \n\n    state_pop  \n7      965479  \n8      701547  \n9    21244317  \n10   10511131  \n20    6035802  \n30    8886025  \n32   19530351  \n33   10381615  \n38   12800922  \n40    5084156  \n46    8501286  \n48    1804291  \n"
    }
   ],
   "source": [
    "# Subset for rows in South Atlantic or Mid-Atlantic regions\n",
    "regions=[\"South Atlantic\",\"Mid-Atlantic\"]\n",
    "south_mid_atlantic =homelessness[homelessness[\"region\"].isin(regions)]\n",
    "\n",
    "# See the result\n",
    "print(south_mid_atlantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region       state  individuals  family_members  state_pop\n2   Mountain     Arizona       7259.0          2606.0    7158024\n4    Pacific  California     109008.0         20964.0   39461588\n28  Mountain      Nevada       7058.0           486.0    3027341\n44  Mountain        Utah       1904.0           972.0    3153550\n"
    }
   ],
   "source": [
    "# The Mojave Desert states\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "region                 state  individuals  family_members  \\\n0   East South Central               Alabama       2570.0           864.0   \n1              Pacific                Alaska       1434.0           582.0   \n2             Mountain               Arizona       7259.0          2606.0   \n3   West South Central              Arkansas       2280.0           432.0   \n4              Pacific            California     109008.0         20964.0   \n5             Mountain              Colorado       7607.0          3250.0   \n6          New England           Connecticut       2280.0          1696.0   \n7       South Atlantic              Delaware        708.0           374.0   \n8       South Atlantic  District of Columbia       3770.0          3134.0   \n9       South Atlantic               Florida      21443.0          9587.0   \n10      South Atlantic               Georgia       6943.0          2556.0   \n11             Pacific                Hawaii       4131.0          2399.0   \n12            Mountain                 Idaho       1297.0           715.0   \n13  East North Central              Illinois       6752.0          3891.0   \n14  East North Central               Indiana       3776.0          1482.0   \n15  West North Central                  Iowa       1711.0          1038.0   \n16  West North Central                Kansas       1443.0           773.0   \n17  East South Central              Kentucky       2735.0           953.0   \n18  West South Central             Louisiana       2540.0           519.0   \n19         New England                 Maine       1450.0          1066.0   \n20      South Atlantic              Maryland       4914.0          2230.0   \n21         New England         Massachusetts       6811.0         13257.0   \n22  East North Central              Michigan       5209.0          3142.0   \n23  West North Central             Minnesota       3993.0          3250.0   \n24  East South Central           Mississippi       1024.0           328.0   \n25  West North Central              Missouri       3776.0          2107.0   \n26            Mountain               Montana        983.0           422.0   \n27  West North Central              Nebraska       1745.0           676.0   \n28            Mountain                Nevada       7058.0           486.0   \n29         New England         New Hampshire        835.0           615.0   \n30        Mid-Atlantic            New Jersey       6048.0          3350.0   \n31            Mountain            New Mexico       1949.0           602.0   \n32        Mid-Atlantic              New York      39827.0         52070.0   \n33      South Atlantic        North Carolina       6451.0          2817.0   \n34  West North Central          North Dakota        467.0            75.0   \n35  East North Central                  Ohio       6929.0          3320.0   \n36  West South Central              Oklahoma       2823.0          1048.0   \n37             Pacific                Oregon      11139.0          3337.0   \n38        Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n39         New England          Rhode Island        747.0           354.0   \n40      South Atlantic        South Carolina       3082.0           851.0   \n41  West North Central          South Dakota        836.0           323.0   \n42  East South Central             Tennessee       6139.0          1744.0   \n43  West South Central                 Texas      19199.0          6111.0   \n44            Mountain                  Utah       1904.0           972.0   \n45         New England               Vermont        780.0           511.0   \n46      South Atlantic              Virginia       3928.0          2047.0   \n47             Pacific            Washington      16424.0          5880.0   \n48      South Atlantic         West Virginia       1021.0           222.0   \n49  East North Central             Wisconsin       2740.0          2167.0   \n50            Mountain               Wyoming        434.0           205.0   \n\n    state_pop     total  p_individuals  \n0     4887681    3434.0       0.748398  \n1      735139    2016.0       0.711310  \n2     7158024    9865.0       0.735834  \n3     3009733    2712.0       0.840708  \n4    39461588  129972.0       0.838704  \n5     5691287   10857.0       0.700654  \n6     3571520    3976.0       0.573441  \n7      965479    1082.0       0.654344  \n8      701547    6904.0       0.546060  \n9    21244317   31030.0       0.691041  \n10   10511131    9499.0       0.730919  \n11    1420593    6530.0       0.632619  \n12    1750536    2012.0       0.644632  \n13   12723071   10643.0       0.634408  \n14    6695497    5258.0       0.718144  \n15    3148618    2749.0       0.622408  \n16    2911359    2216.0       0.651173  \n17    4461153    3688.0       0.741594  \n18    4659690    3059.0       0.830337  \n19    1339057    2516.0       0.576312  \n20    6035802    7144.0       0.687850  \n21    6882635   20068.0       0.339396  \n22    9984072    8351.0       0.623758  \n23    5606249    7243.0       0.551291  \n24    2981020    1352.0       0.757396  \n25    6121623    5883.0       0.641849  \n26    1060665    1405.0       0.699644  \n27    1925614    2421.0       0.720777  \n28    3027341    7544.0       0.935578  \n29    1353465    1450.0       0.575862  \n30    8886025    9398.0       0.643541  \n31    2092741    2551.0       0.764014  \n32   19530351   91897.0       0.433387  \n33   10381615    9268.0       0.696051  \n34     758080     542.0       0.861624  \n35   11676341   10249.0       0.676066  \n36    3940235    3871.0       0.729269  \n37    4181886   14476.0       0.769481  \n38   12800922   13512.0       0.604130  \n39    1058287    1101.0       0.678474  \n40    5084156    3933.0       0.783626  \n41     878698    1159.0       0.721311  \n42    6771631    7883.0       0.778764  \n43   28628666   25310.0       0.758554  \n44    3153550    2876.0       0.662031  \n45     624358    1291.0       0.604183  \n46    8501286    5975.0       0.657406  \n47    7523869   22304.0       0.736370  \n48    1804291    1243.0       0.821400  \n49    5807406    4907.0       0.558386  \n50     577601     639.0       0.679186  \n"
    }
   ],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "homelessness[\"total\"]=homelessness[\"individuals\"]+homelessness[\"family_members\"]\n",
    "\n",
    "# Add p_individuals col as proportion of individuals\n",
    "homelessness[\"p_individuals\"]=homelessness[\"individuals\"]/homelessness[\"total\"]\n",
    "\n",
    "# See the result\n",
    "print(homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "state  indiv_per_10k\n8   District of Columbia      53.738381\n11                Hawaii      29.079406\n4             California      27.623825\n37                Oregon      26.636307\n28                Nevada      23.314189\n47            Washington      21.829195\n32              New York      20.392363\n"
    }
   ],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"]>20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\",ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\",\"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result)"
   ]
  },
  {
   "source": [
    "## Chapter 2: Aggregating Data\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales =pd.read_csv('../datasets/sales_subset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "store type  department        date  weekly_sales  is_holiday  \\\n0      1    A           1  2010-02-05      24924.50       False   \n1      1    A           1  2010-03-05      21827.90       False   \n2      1    A           1  2010-04-02      57258.43       False   \n3      1    A           1  2010-05-07      17413.94       False   \n4      1    A           1  2010-06-04      17558.09       False   \n\n   temperature_c  fuel_price_usd_per_l  unemployment  \n0       5.727778              0.679451         8.106  \n1       8.055556              0.693452         8.106  \n2      16.816667              0.718284         7.808  \n3      22.527778              0.748928         7.808  \n4      27.050000              0.714586         7.808  \n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 10774 entries, 0 to 10773\nData columns (total 9 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   store                 10774 non-null  int64  \n 1   type                  10774 non-null  object \n 2   department            10774 non-null  int64  \n 3   date                  10774 non-null  object \n 4   weekly_sales          10774 non-null  float64\n 5   is_holiday            10774 non-null  bool   \n 6   temperature_c         10774 non-null  float64\n 7   fuel_price_usd_per_l  10774 non-null  float64\n 8   unemployment          10774 non-null  float64\ndtypes: bool(1), float64(4), int64(2), object(2)\nmemory usage: 683.9+ KB\nNone\n23843.95014850566\n12049.064999999999\n"
    }
   ],
   "source": [
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())\n",
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(sales['weekly_sales'].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(sales['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2012-10-26\n2010-02-05\n"
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(sales['date'].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales['date'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16.58333333333334\n"
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "temperature_c           16.583333\nfuel_price_usd_per_l     0.073176\nunemployment             0.565000\ndtype: float64\n"
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\",\"fuel_price_usd_per_l\",\"unemployment\"]].agg(iqr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "temperature_c  fuel_price_usd_per_l  unemployment\niqr         16.583333              0.073176         0.565\nmedian      16.966667              0.743381         8.099\n"
    }
   ],
   "source": [
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_1_1=sales[(sales.department==1) & (sales.store==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "store type  department        date  weekly_sales  is_holiday  \\\n0       1    A           1  2010-02-05      24924.50       False   \n1       1    A           1  2010-03-05      21827.90       False   \n2       1    A           1  2010-04-02      57258.43       False   \n3       1    A           1  2010-05-07      17413.94       False   \n4       1    A           1  2010-06-04      17558.09       False   \n5       1    A           1  2010-07-02      16333.14       False   \n6       1    A           1  2010-08-06      17508.41       False   \n7       1    A           1  2010-09-03      16241.78       False   \n8       1    A           1  2010-10-01      20094.19       False   \n9       1    A           1  2010-11-05      34238.88       False   \n10      1    A           1  2010-12-03      22517.56       False   \n11      1    A           1  2011-01-07      15984.24       False   \n\n    temperature_c  fuel_price_usd_per_l  unemployment  \n0        5.727778              0.679451         8.106  \n1        8.055556              0.693452         8.106  \n2       16.816667              0.718284         7.808  \n3       22.527778              0.748928         7.808  \n4       27.050000              0.714586         7.808  \n5       27.172222              0.705076         7.787  \n6       30.644444              0.693980         7.787  \n7       27.338889              0.680772         7.787  \n8       22.161111              0.687640         7.838  \n9       14.855556              0.710359         7.838  \n10       9.594444              0.715378         7.838  \n11       9.038889              0.786176         7.742  \n          date  weekly_sales  cum_weekly_sales  cum_max_sales\n0   2010-02-05      24924.50          24924.50       24924.50\n1   2010-03-05      21827.90          46752.40       24924.50\n2   2010-04-02      57258.43         104010.83       57258.43\n3   2010-05-07      17413.94         121424.77       57258.43\n4   2010-06-04      17558.09         138982.86       57258.43\n5   2010-07-02      16333.14         155316.00       57258.43\n6   2010-08-06      17508.41         172824.41       57258.43\n7   2010-09-03      16241.78         189066.19       57258.43\n8   2010-10-01      20094.19         209160.38       57258.43\n9   2010-11-05      34238.88         243399.26       57258.43\n10  2010-12-03      22517.56         265916.82       57258.43\n11  2011-01-07      15984.24         281901.06       57258.43\n"
    }
   ],
   "source": [
    "# Sort sales_1_1 by date\n",
    "print(sales_1_1)\n",
    "sales_1_1 = sales_1_1.sort_values('date')\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "store type  department        date  weekly_sales  is_holiday  \\\n0         1    A           1  2010-02-05      24924.50       False   \n901       2    A           1  2010-02-05      35034.06       False   \n1798      4    A           1  2010-02-05      38724.42       False   \n2699      6    A           1  2010-02-05      25619.00       False   \n3593     10    B           1  2010-02-05      40212.84       False   \n\n      temperature_c  fuel_price_usd_per_l  unemployment  \n0          5.727778              0.679451         8.106  \n901        4.550000              0.679451         8.324  \n1798       6.533333              0.686319         8.623  \n2699       4.683333              0.679451         7.259  \n3593      12.411111              0.782478         9.765  \n    store type  department        date  weekly_sales  is_holiday  \\\n0       1    A           1  2010-02-05      24924.50       False   \n12      1    A           2  2010-02-05      50605.27       False   \n24      1    A           3  2010-02-05      13740.12       False   \n36      1    A           4  2010-02-05      39954.04       False   \n48      1    A           5  2010-02-05      32229.38       False   \n\n    temperature_c  fuel_price_usd_per_l  unemployment  \n0        5.727778              0.679451         8.106  \n12       5.727778              0.679451         8.106  \n24       5.727778              0.679451         8.106  \n36       5.727778              0.679451         8.106  \n48       5.727778              0.679451         8.106  \n498     2010-09-10\n691     2011-11-25\n2315    2010-02-12\n6735    2012-09-07\n6810    2010-12-31\n6815    2012-02-10\n6820    2011-09-09\nName: date, dtype: object\n"
    }
   ],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=\"store\")\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\",\"department\"])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows that are holiday weeks and drop duplicate dates\n",
    "holiday_dates = sales[sales[\"is_holiday\"]].drop_duplicates(subset=\"date\")\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "A    11\nB     1\nName: type, dtype: int64\nA    0.916667\nB    0.083333\nName: type, dtype: float64\n41    12\n30    12\n23    12\n24    12\n25    12\n      ..\n37    10\n48     8\n50     6\n39     4\n43     2\nName: department, Length: 80, dtype: int64\n41    0.012917\n30    0.012917\n23    0.012917\n24    0.012917\n25    0.012917\n        ...   \n37    0.010764\n48    0.008611\n50    0.006459\n39    0.004306\n43    0.002153\nName: department, Length: 80, dtype: float64\n"
    }
   ],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types['type'].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Get the proportion of stores of each type\n",
    "store_props = store_types['type'].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts[\"department\"].value_counts()\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Get the proportion of departments of each number and sort\n",
    "dept_props_sorted = store_depts[\"department\"].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.9097747 0.0902253 0.       ]\n"
    }
   ],
   "source": [
    "# Calc total weekly sales\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "type\nA    0.909775\nB    0.090225\nName: weekly_sales, dtype: float64\n"
    }
   ],
   "source": [
    "# Group by type; calc total weekly sales\n",
    "sales_by_type = sales.groupby(\"type\")['weekly_sales'].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = sales_by_type/sales_by_type.sum()\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "type  is_holiday\nA     False         2.336927e+08\n      True          2.360181e+04\nB     False         2.317678e+07\n      True          1.621410e+03\nName: weekly_sales, dtype: float64\n"
    }
   ],
   "source": [
    "# Group by type and is_holiday; calc total weekly sales\n",
    "sales_by_type_is_holiday = sales.groupby([\"type\",\"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "amin       amax          mean    median\ntype                                           \nA    -1098.0  293966.05  23674.667242  11943.92\nB     -798.0  232558.51  25696.678370  13336.08\n     unemployment                         fuel_price_usd_per_l            \\\n             amin   amax      mean median                 amin      amax   \ntype                                                                       \nA           3.879  8.992  7.972611  8.067             0.664129  1.107410   \nB           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n\n                          \n          mean    median  \ntype                      \nA     0.744619  0.735455  \nB     0.805858  0.803348  \n"
    }
   ],
   "source": [
    "# Import NumPy with the alias np\n",
    "import numpy as np\n",
    "agg_ops=[np.min,np.max,np.mean,np.median]\n",
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg(agg_ops)\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[\"unemployment\",\"fuel_price_usd_per_l\"].agg(agg_ops)\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "source": [
    "* Pivot tables\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "store type  department        date  weekly_sales  is_holiday  \\\n0      1    A           1  2010-02-05      24924.50       False   \n1      1    A           1  2010-03-05      21827.90       False   \n2      1    A           1  2010-04-02      57258.43       False   \n3      1    A           1  2010-05-07      17413.94       False   \n4      1    A           1  2010-06-04      17558.09       False   \n\n   temperature_c  fuel_price_usd_per_l  unemployment  \n0       5.727778              0.679451         8.106  \n1       8.055556              0.693452         8.106  \n2      16.816667              0.718284         7.808  \n3      22.527778              0.748928         7.808  \n4      27.050000              0.714586         7.808  \nafter pivot\n       weekly_sales\ntype              \nA     23674.667242\nB     25696.678370\n      weekly_sales\ntype              \nA     23674.667242\nB     25696.678370\n"
    }
   ],
   "source": [
    "print(sales.head())\n",
    "# Pivot for mean weekly_sales for each store type\n",
    "mean_sales_by_type = sales.pivot_table(index=\"type\", values=\"weekly_sales\")\n",
    "# it means; group by type and sum weekly_sales then pivot result.\n",
    "print('after pivot\\n',mean_sales_by_type.head())\n",
    "# Print mean_sales_by_type\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mean       median\n      weekly_sales weekly_sales\ntype                           \nA     23674.667242     11943.92\nB     25696.678370     13336.08\n"
    }
   ],
   "source": [
    "# Import NumPy as np\n",
    "import numpy as np\n",
    "\n",
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(index=\"type\", values=\"weekly_sales\", aggfunc=[np.mean, np.median])\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "is_holiday         False      True \ntype                               \nA           23768.583523  590.04525\nB           25751.980533  810.70500\n"
    }
   ],
   "source": [
    "# Pivot for mean weekly_sales by store type and holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(index=[\"type\"], columns=[\"is_holiday\"], values=\"weekly_sales\")\n",
    "\n",
    "# Print mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "department            1              2             3             4   \\\ntype                                                                  \nA           30961.725379   67600.158788  17160.002955  44285.399091   \nB           44050.626667  112958.526667  30580.655000  51219.654167   \n\ndepartment            5             6             7             8   \\\ntype                                                                 \nA           34821.011364   7136.292652  38454.336818  48583.475303   \nB           63236.875000  10717.297500  52909.653333  90733.753333   \n\ndepartment            9             10  ...            90            91  \\\ntype                                    ...                               \nA           30120.449924  30930.456364  ...  85776.905909  70423.165227   \nB           66679.301667  48595.126667  ...  14780.210000  13199.602500   \n\ndepartment             92            93            94             95  \\\ntype                                                                   \nA           139722.204773  53413.633939  60081.155303  123933.787121   \nB            50859.278333   1466.274167    161.445833   77082.102500   \n\ndepartment            96            97            98          99  \ntype                                                              \nA           21367.042857  28471.266970  12875.423182  379.123659  \nB            9528.538333   5828.873333    217.428333    0.000000  \n\n[2 rows x 80 columns]\n"
    }
   ],
   "source": [
    "# Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"type\",columns=\"department\", fill_value=0))"
   ]
  },
  {
   "source": [
    "* *** margins, sum all rows and cols"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "type                   A              B           All\ndepartment                                           \n1           30961.725379   44050.626667  32052.467153\n2           67600.158788  112958.526667  71380.022778\n3           17160.002955   30580.655000  18278.390625\n4           44285.399091   51219.654167  44863.253681\n5           34821.011364   63236.875000  37189.000000\n...                  ...            ...           ...\n96          21367.042857    9528.538333  20337.607681\n97          28471.266970    5828.873333  26584.400833\n98          12875.423182     217.428333  11820.590278\n99            379.123659       0.000000    379.123659\nAll         23674.667242   25696.678370  23843.950149\n\n[81 rows x 3 columns]\n"
    }
   ],
   "source": [
    "# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols\n",
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"department\", columns=\"type\", fill_value=0,margins=True))"
   ]
  },
  {
   "source": [
    "## Chapter 3 Slicing and indexing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures=pd.read_csv('../datasets/temperatures (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "temperatures\n        Unnamed: 0        date     city        country  avg_temp_c\n0               0  2000-01-01  Abidjan  Côte D'Ivoire      27.293\n1               1  2000-02-01  Abidjan  Côte D'Ivoire      27.685\n2               2  2000-03-01  Abidjan  Côte D'Ivoire      29.061\n3               3  2000-04-01  Abidjan  Côte D'Ivoire      28.162\n4               4  2000-05-01  Abidjan  Côte D'Ivoire      27.547\n...           ...         ...      ...            ...         ...\n16495       16495  2013-05-01     Xian          China      18.979\n16496       16496  2013-06-01     Xian          China      23.522\n16497       16497  2013-07-01     Xian          China      25.251\n16498       16498  2013-08-01     Xian          China      24.528\n16499       16499  2013-09-01     Xian          China         NaN\n\n[16500 rows x 5 columns]\ntemperatures_ind\n          Unnamed: 0        date        country  avg_temp_c\ncity                                                      \nAbidjan           0  2000-01-01  Côte D'Ivoire      27.293\nAbidjan           1  2000-02-01  Côte D'Ivoire      27.685\nAbidjan           2  2000-03-01  Côte D'Ivoire      29.061\nAbidjan           3  2000-04-01  Côte D'Ivoire      28.162\nAbidjan           4  2000-05-01  Côte D'Ivoire      27.547\n...             ...         ...            ...         ...\nXian          16495  2013-05-01          China      18.979\nXian          16496  2013-06-01          China      23.522\nXian          16497  2013-07-01          China      25.251\nXian          16498  2013-08-01          China      24.528\nXian          16499  2013-09-01          China         NaN\n\n[16500 rows x 4 columns]\ntemperatures_ind.reset_index()\n           city  Unnamed: 0        date        country  avg_temp_c\n0      Abidjan           0  2000-01-01  Côte D'Ivoire      27.293\n1      Abidjan           1  2000-02-01  Côte D'Ivoire      27.685\n2      Abidjan           2  2000-03-01  Côte D'Ivoire      29.061\n3      Abidjan           3  2000-04-01  Côte D'Ivoire      28.162\n4      Abidjan           4  2000-05-01  Côte D'Ivoire      27.547\n...        ...         ...         ...            ...         ...\n16495     Xian       16495  2013-05-01          China      18.979\n16496     Xian       16496  2013-06-01          China      23.522\n16497     Xian       16497  2013-07-01          China      25.251\n16498     Xian       16498  2013-08-01          China      24.528\n16499     Xian       16499  2013-09-01          China         NaN\n\n[16500 rows x 5 columns]\ntemperatures_ind.reset_index(drop=True)\n        Unnamed: 0        date        country  avg_temp_c\n0               0  2000-01-01  Côte D'Ivoire      27.293\n1               1  2000-02-01  Côte D'Ivoire      27.685\n2               2  2000-03-01  Côte D'Ivoire      29.061\n3               3  2000-04-01  Côte D'Ivoire      28.162\n4               4  2000-05-01  Côte D'Ivoire      27.547\n...           ...         ...            ...         ...\n16495       16495  2013-05-01          China      18.979\n16496       16496  2013-06-01          China      23.522\n16497       16497  2013-07-01          China      25.251\n16498       16498  2013-08-01          China      24.528\n16499       16499  2013-09-01          China         NaN\n\n[16500 rows x 4 columns]\n"
    }
   ],
   "source": [
    "# Look at temperatures\n",
    "print('temperatures\\n',temperatures)\n",
    "\n",
    "# Index temperatures by city\n",
    "temperatures_ind = temperatures.set_index('city')\n",
    "\n",
    "# Look at temperatures_ind\n",
    "print('temperatures_ind\\n',temperatures_ind)\n",
    "\n",
    "# Reset the index, keeping its contents\n",
    "print('temperatures_ind.reset_index()\\n',temperatures_ind.reset_index())\n",
    "\n",
    "# Reset the index, dropping its contents\n",
    "print('temperatures_ind.reset_index(drop=True)\\n',temperatures_ind.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0        date              city country  avg_temp_c\n10725       10725  2000-01-01            Moscow  Russia      -7.313\n10726       10726  2000-02-01            Moscow  Russia      -3.551\n10727       10727  2000-03-01            Moscow  Russia      -1.661\n10728       10728  2000-04-01            Moscow  Russia      10.096\n10729       10729  2000-05-01            Moscow  Russia      10.357\n...           ...         ...               ...     ...         ...\n13360       13360  2013-05-01  Saint Petersburg  Russia      12.355\n13361       13361  2013-06-01  Saint Petersburg  Russia      17.185\n13362       13362  2013-07-01  Saint Petersburg  Russia      17.234\n13363       13363  2013-08-01  Saint Petersburg  Russia      17.153\n13364       13364  2013-09-01  Saint Petersburg  Russia         NaN\n\n[330 rows x 5 columns]\n                  Unnamed: 0        date country  avg_temp_c\ncity                                                        \nMoscow                 10725  2000-01-01  Russia      -7.313\nMoscow                 10726  2000-02-01  Russia      -3.551\nMoscow                 10727  2000-03-01  Russia      -1.661\nMoscow                 10728  2000-04-01  Russia      10.096\nMoscow                 10729  2000-05-01  Russia      10.357\n...                      ...         ...     ...         ...\nSaint Petersburg       13360  2013-05-01  Russia      12.355\nSaint Petersburg       13361  2013-06-01  Russia      17.185\nSaint Petersburg       13362  2013-07-01  Russia      17.234\nSaint Petersburg       13363  2013-08-01  Russia      17.153\nSaint Petersburg       13364  2013-09-01  Russia         NaN\n\n[330 rows x 4 columns]\n"
    }
   ],
   "source": [
    "# Make a list of cities to subset on\n",
    "cities = [\"Moscow\",\"Saint Petersburg\"]\n",
    "\n",
    "# Subset temperatures using square brackets\n",
    "print(temperatures[temperatures[\"city\"].isin(cities)])\n",
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[cities])"
   ]
  },
  {
   "source": [
    "* *** very nice sample for loc learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0        date  avg_temp_c\ncountry  city                                              \nBrazil   Rio De Janeiro       12540  2000-01-01      25.974\n         Rio De Janeiro       12541  2000-02-01      26.699\n         Rio De Janeiro       12542  2000-03-01      26.270\n         Rio De Janeiro       12543  2000-04-01      25.750\n         Rio De Janeiro       12544  2000-05-01      24.356\n...                             ...         ...         ...\nPakistan Lahore                8575  2013-05-01      33.457\n         Lahore                8576  2013-06-01      34.456\n         Lahore                8577  2013-07-01      33.279\n         Lahore                8578  2013-08-01      31.511\n         Lahore                8579  2013-09-01         NaN\n\n[330 rows x 3 columns]\n"
    }
   ],
   "source": [
    "# Index temperatures by country & city\n",
    "temperatures_ind = temperatures.set_index([\"country\",\"city\"])\n",
    "\n",
    "# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n",
    "rows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"),(\"Pakistan\", \"Lahore\")]\n",
    "\n",
    "# Subset for rows to keep\n",
    "print(temperatures_ind.loc[rows_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0        date  avg_temp_c\ncountry     city                                      \nAfghanistan Kabul         7260  2000-01-01       3.326\n            Kabul         7261  2000-02-01       3.454\n            Kabul         7262  2000-03-01       9.612\n            Kabul         7263  2000-04-01      17.925\n            Kabul         7264  2000-05-01      24.658\n...                        ...         ...         ...\nZimbabwe    Harare        5605  2013-05-01      18.298\n            Harare        5606  2013-06-01      17.020\n            Harare        5607  2013-07-01      16.299\n            Harare        5608  2013-08-01      19.232\n            Harare        5609  2013-09-01         NaN\n\n[16500 rows x 3 columns]\n                       Unnamed: 0        date  avg_temp_c\ncountry       city                                       \nCôte D'Ivoire Abidjan           0  2000-01-01      27.293\n              Abidjan           1  2000-02-01      27.685\n              Abidjan           2  2000-03-01      29.061\n              Abidjan           3  2000-04-01      28.162\n              Abidjan           4  2000-05-01      27.547\n...                           ...         ...         ...\nChina         Xian          16495  2013-05-01      18.979\n              Xian          16496  2013-06-01      23.522\n              Xian          16497  2013-07-01      25.251\n              Xian          16498  2013-08-01      24.528\n              Xian          16499  2013-09-01         NaN\n\n[16500 rows x 3 columns]\n                    Unnamed: 0        date  avg_temp_c\ncountry     city                                      \nAfghanistan Kabul         7260  2000-01-01       3.326\n            Kabul         7261  2000-02-01       3.454\n            Kabul         7262  2000-03-01       9.612\n            Kabul         7263  2000-04-01      17.925\n            Kabul         7264  2000-05-01      24.658\n...                        ...         ...         ...\nZimbabwe    Harare        5605  2013-05-01      18.298\n            Harare        5606  2013-06-01      17.020\n            Harare        5607  2013-07-01      16.299\n            Harare        5608  2013-08-01      19.232\n            Harare        5609  2013-09-01         NaN\n\n[16500 rows x 3 columns]\n"
    }
   ],
   "source": [
    "#print(temperatures_ind.index.values)\n",
    "# Sort temperatures_ind by index values\n",
    "print(temperatures_ind.sort_index())\n",
    "\n",
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level=[\"city\"]))\n",
    "\n",
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level=[\"country\",\"city\"], ascending=[True,False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0        date  avg_temp_c\ncountry  city                                                \nPakistan Faisalabad              4785  2000-01-01      12.792\n         Faisalabad              4786  2000-02-01      14.339\n         Faisalabad              4787  2000-03-01      20.309\n         Faisalabad              4788  2000-04-01      29.072\n         Faisalabad              4789  2000-05-01      34.845\n...                               ...         ...         ...\nRussia   Saint Petersburg       13360  2013-05-01      12.355\n         Saint Petersburg       13361  2013-06-01      17.185\n         Saint Petersburg       13362  2013-07-01      17.234\n         Saint Petersburg       13363  2013-08-01      17.153\n         Saint Petersburg       13364  2013-09-01         NaN\n\n[1155 rows x 3 columns]\n                    Unnamed: 0        date  avg_temp_c\ncountry city                                          \nMexico  Mexico           10230  2000-01-01      12.694\n        Mexico           10231  2000-02-01      14.677\n        Mexico           10232  2000-03-01      17.376\n        Mexico           10233  2000-04-01      18.294\n        Mexico           10234  2000-05-01      18.562\n...                        ...         ...         ...\nMorocco Casablanca        3130  2013-05-01      19.217\n        Casablanca        3131  2013-06-01      23.649\n        Casablanca        3132  2013-07-01      27.488\n        Casablanca        3133  2013-08-01      27.952\n        Casablanca        3134  2013-09-01         NaN\n\n[330 rows x 3 columns]\n                 Unnamed: 0        date  avg_temp_c\ncountry  city                                      \nPakistan Lahore        8415  2000-01-01      12.792\n         Lahore        8416  2000-02-01      14.339\n         Lahore        8417  2000-03-01      20.309\n         Lahore        8418  2000-04-01      29.072\n         Lahore        8419  2000-05-01      34.845\n...                     ...         ...         ...\nRussia   Moscow       10885  2013-05-01      16.152\n         Moscow       10886  2013-06-01      18.718\n         Moscow       10887  2013-07-01      18.136\n         Moscow       10888  2013-08-01      17.485\n         Moscow       10889  2013-09-01         NaN\n\n[660 rows x 3 columns]\n"
    }
   ],
   "source": [
    "#Slicing and subsetting with .loc and .iloc\n",
    "temperatures_ind = temperatures.set_index([\"country\",\"city\"])\n",
    "# Sort the index of temperatures_ind\n",
    "temperatures_srt = temperatures_ind.sort_index()\n",
    "\n",
    "# Subset rows from Pakistan to Russia\n",
    "print(temperatures_srt.loc['Pakistan':'Russia'])\n",
    "\n",
    "# Try to subset rows from Lahore to Moscow\n",
    "print(temperatures_srt.loc['Lahore':'Moscow'])\n",
    "\n",
    "# Subset rows from Pakistan, Lahore to Russia, Moscow\n",
    "print(temperatures_srt.loc[('Pakistan','Lahore'):('Russia','Moscow')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0        date  avg_temp_c\ncountry city                                         \nIndia   Hyderabad        5940  2000-01-01      23.779\n        Hyderabad        5941  2000-02-01      25.826\n        Hyderabad        5942  2000-03-01      28.821\n        Hyderabad        5943  2000-04-01      32.698\n        Hyderabad        5944  2000-05-01      32.438\n...                       ...         ...         ...\nIraq    Baghdad          1150  2013-05-01      28.673\n        Baghdad          1151  2013-06-01      33.803\n        Baghdad          1152  2013-07-01      36.392\n        Baghdad          1153  2013-08-01      35.463\n        Baghdad          1154  2013-09-01         NaN\n\n[2145 rows x 3 columns]\n                          date  avg_temp_c\ncountry     city                          \nAfghanistan Kabul   2000-01-01       3.326\n            Kabul   2000-02-01       3.454\n            Kabul   2000-03-01       9.612\n            Kabul   2000-04-01      17.925\n            Kabul   2000-05-01      24.658\n...                        ...         ...\nZimbabwe    Harare  2013-05-01      18.298\n            Harare  2013-06-01      17.020\n            Harare  2013-07-01      16.299\n            Harare  2013-08-01      19.232\n            Harare  2013-09-01         NaN\n\n[16500 rows x 2 columns]\n                         date  avg_temp_c\ncountry city                             \nIndia   Hyderabad  2000-01-01      23.779\n        Hyderabad  2000-02-01      25.826\n        Hyderabad  2000-03-01      28.821\n        Hyderabad  2000-04-01      32.698\n        Hyderabad  2000-05-01      32.438\n...                       ...         ...\nIraq    Baghdad    2013-05-01      28.673\n        Baghdad    2013-06-01      33.803\n        Baghdad    2013-07-01      36.392\n        Baghdad    2013-08-01      35.463\n        Baghdad    2013-09-01         NaN\n\n[2145 rows x 2 columns]\n"
    }
   ],
   "source": [
    "# Subset rows from India, Hyderabad to Iraq, Baghdad\n",
    "print(temperatures_srt.loc[('India','Hyderabad'):('Iraq','Baghdad')])\n",
    "# Subset columns from date to avg_temp_c\n",
    "print(temperatures_srt.loc[:,'date':'avg_temp_c'])\n",
    "\n",
    "# Subset in both directions at once\n",
    "print(temperatures_srt.loc[('India','Hyderabad'):('Iraq','Baghdad'),'date':'avg_temp_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[    0     1     2 ... 16497 16498 16499]\n       Unnamed: 0        date     city        country  avg_temp_c\n120           120  2010-01-01  Abidjan  Côte D'Ivoire      28.270\n121           121  2010-02-01  Abidjan  Côte D'Ivoire      29.262\n122           122  2010-03-01  Abidjan  Côte D'Ivoire      29.596\n123           123  2010-04-01  Abidjan  Côte D'Ivoire      29.068\n124           124  2010-05-01  Abidjan  Côte D'Ivoire      28.258\n...           ...         ...      ...            ...         ...\n16474       16474  2011-08-01     Xian          China      23.069\n16475       16475  2011-09-01     Xian          China      16.775\n16476       16476  2011-10-01     Xian          China      12.587\n16477       16477  2011-11-01     Xian          China       7.543\n16478       16478  2011-12-01     Xian          China      -0.490\n\n[2400 rows x 5 columns]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Cannot get left slice bound for non-unique label: '2010-01-01'\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-b48270857a48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemperatures_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2010-01-01'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'2011'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1911\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1912\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1913\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1795\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1796\u001b[1;33m         indexer = labels.slice_indexer(\n\u001b[0m\u001b[0;32m   1797\u001b[0m             \u001b[0mslice_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1798\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   4710\u001b[0m         \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4711\u001b[0m         \"\"\"\n\u001b[1;32m-> 4712\u001b[1;33m         \u001b[0mstart_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_locs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4714\u001b[0m         \u001b[1;31m# return a slice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   4923\u001b[0m         \u001b[0mstart_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4925\u001b[1;33m             \u001b[0mstart_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4926\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart_slice\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4927\u001b[0m             \u001b[0mstart_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   4855\u001b[0m                 \u001b[0mslc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_indices_to_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4856\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4857\u001b[1;33m                 raise KeyError(\n\u001b[0m\u001b[0;32m   4858\u001b[0m                     \u001b[1;34mf\"Cannot get {side} slice bound for non-unique \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4859\u001b[0m                     \u001b[1;34mf\"label: {repr(original_label)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Cannot get left slice bound for non-unique label: '2010-01-01'\""
     ]
    }
   ],
   "source": [
    "print(temperatures.index.values)\n",
    "# Use Boolean conditions to subset temperatures for rows in 2010 and 2011\n",
    "temperatures_bool = temperatures[(temperatures[\"date\"] >= \"2010\") & (temperatures[\"date\"] < \"2012\")]\n",
    "print(temperatures_bool)\n",
    "\n",
    "# Set date as an index\n",
    "temperatures_ind = temperatures.set_index(\"date\")\n",
    "    \n",
    "# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\n",
    "print(temperatures_ind.loc['2010-01-01':'2011'])\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\n",
    "print(temperatures_ind.loc['2010-08-01':'2011-02-28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "date\n22  2001-11-01\n   Unnamed: 0        date     city        country  avg_temp_c\n0           0  2000-01-01  Abidjan  Côte D'Ivoire      27.293\n1           1  2000-02-01  Abidjan  Côte D'Ivoire      27.685\n2           2  2000-03-01  Abidjan  Côte D'Ivoire      29.061\n3           3  2000-04-01  Abidjan  Côte D'Ivoire      28.162\n4           4  2000-05-01  Abidjan  Côte D'Ivoire      27.547\n          city        country\n0      Abidjan  Côte D'Ivoire\n1      Abidjan  Côte D'Ivoire\n2      Abidjan  Côte D'Ivoire\n3      Abidjan  Côte D'Ivoire\n4      Abidjan  Côte D'Ivoire\n...        ...            ...\n16495     Xian          China\n16496     Xian          China\n16497     Xian          China\n16498     Xian          China\n16499     Xian          China\n\n[16500 rows x 2 columns]\n      city        country\n0  Abidjan  Côte D'Ivoire\n1  Abidjan  Côte D'Ivoire\n2  Abidjan  Côte D'Ivoire\n3  Abidjan  Côte D'Ivoire\n4  Abidjan  Côte D'Ivoire\n"
    }
   ],
   "source": [
    "# Get 23rd row, 2nd column (index 22, 1)\n",
    "print(temperatures.iloc[22:23, 1:2])\n",
    "\n",
    "# Use slicing to get the first 5 rows\n",
    "print(temperatures.iloc[0:5])\n",
    "\n",
    "# Use slicing to get columns 3 to 4\n",
    "print(temperatures.iloc[:,2:4])\n",
    "\n",
    "# Use slicing in both directions at once\n",
    "print(temperatures.iloc[0:5,2:4 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-57b06419c0b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Add a year column to temperatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtemperatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"year\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemperatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemperatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Pivot avg_temp_c by country and city vs year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtemp_by_country_city_vs_year\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemperatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"avg_temp_c\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"year\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"country\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"city\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5268\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5269\u001b[0m         ):\n\u001b[1;32m-> 5270\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5271\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeProperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# Add a year column to temperatures\n",
    "temperatures[\"year\"]=temperatures[\"date\"].dt.year\n",
    "print(temperatures)\n",
    "# Pivot avg_temp_c by country and city vs year\n",
    "temp_by_country_city_vs_year = temperatures.pivot_table(values=\"avg_temp_c\", columns=\"year\",index=[\"country\",\"city\"])\n",
    "\n",
    "# See the result\n",
    "print(temp_by_country_city_vs_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}