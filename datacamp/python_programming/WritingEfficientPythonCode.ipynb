{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600533418211",
   "display_name": "Python 3.8.3 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Chapter 1:Foundations for efficiencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* Q: In the context of this course, what is meant by efficient Python code?\n",
    "* A: Code that executes quickly for the task at hand, minimizes the memory footprint and follows Python's coding style principles.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Jerry', 'Kramer', 'Elaine', 'George', 'Newman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Kramer', 'Elaine', 'George', 'Newman']\n"
    }
   ],
   "source": [
    "# Print the list created using the Non-Pythonic approach\n",
    "i = 0\n",
    "new_list= []\n",
    "while i < len(names):\n",
    "    if len(names[i]) >= 6:\n",
    "        new_list.append(names[i])\n",
    "    i += 1\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Kramer', 'Elaine', 'George', 'Newman']\n"
    }
   ],
   "source": [
    "# Print the list created by looping over the contents of names\n",
    "better_list = []\n",
    "for name in names:\n",
    "    if len(name) >= 6:\n",
    "        better_list.append(name)\n",
    "print(better_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Kramer', 'Elaine', 'George', 'Newman']\n"
    }
   ],
   "source": [
    "# Print the list created by using list comprehension\n",
    "best_list = [name for name in names if len(name) >= 6]\n",
    "print(best_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'range'>\n[0, 1, 2, 3, 4, 5]\n[1, 3, 5, 7, 9, 11]\n"
    }
   ],
   "source": [
    "# Create a range object that goes from 0 to 5\n",
    "nums = range(6)\n",
    "print(type(nums))\n",
    "\n",
    "# Convert nums to a list\n",
    "nums_list = list(nums)\n",
    "print(nums_list)\n",
    "\n",
    "# Create a new list of odd numbers from 1 to 11 by unpacking a range object\n",
    "nums_list2 = [*range(1,12,2)]\n",
    "print(nums_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, 'Jerry'), (1, 'Kramer'), (2, 'Elaine'), (3, 'George'), (4, 'Newman')]\n[(0, 'Jerry'), (1, 'Kramer'), (2, 'Elaine'), (3, 'George'), (4, 'Newman')]\n[(1, 'Jerry'), (2, 'Kramer'), (3, 'Elaine'), (4, 'George'), (5, 'Newman')]\n"
    }
   ],
   "source": [
    "# Rewrite the for loop to use enumerate\n",
    "indexed_names = []\n",
    "for i,name in enumerate(names):\n",
    "    index_name = (i,name)\n",
    "    indexed_names.append(index_name) \n",
    "print(indexed_names)\n",
    "\n",
    "# Rewrite the above for loop using list comprehension\n",
    "indexed_names_comp = [(i,name) for i,name in enumerate(names)]\n",
    "print(indexed_names_comp)\n",
    "\n",
    "# Unpack an enumerate object with a starting index of one\n",
    "indexed_names_unpack = [*enumerate(names, 1)]\n",
    "print(indexed_names_unpack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'map'>\n['JERRY', 'KRAMER', 'ELAINE', 'GEORGE', 'NEWMAN']\n"
    }
   ],
   "source": [
    "# Use map to apply str.upper to each element in names\n",
    "names_map  = map(str.upper, names)\n",
    "\n",
    "# Print the type of the names_map\n",
    "print(type(names_map))\n",
    "\n",
    "# Unpack names_map into a list\n",
    "names_uppercase = [*names_map]\n",
    "\n",
    "# Print the list created above\n",
    "print(names_uppercase)"
   ]
  },
  {
   "source": [
    "* Basic 1-D indexing (lists)\n",
    "    * nums=[-2,-1,0,1,2]\n",
    "    * nums[-1] -> 2\n",
    "    * nums[1:4] -> [-1,0,1]\n",
    "* Basic 1-D indexing (arrays)\n",
    "    * numps_np=np.arry(nums)\n",
    "    * numps_np[-1] -> 2\n",
    "    * numps_np[1:4] -> array([-1,0,1])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* Basic 2-D indexing (lists)\n",
    "    * nums2=[[1,2,3],[4,5,6]]\n",
    "    * nums2[0][1] -> 2\n",
    "    * [row[0] for row in nums2] -> [1,4]\n",
    "    * nums2[1:4] -> [-1,0,1]\n",
    "* Basic 2-D indexing (arrays)\n",
    "    * numps2_np=np.arry(nums)\n",
    "    * numps2_np[0,1] -> 2\n",
    "    * numps2_np[:,0] -> array([1,4])\n",
    "    * numps2_np[1:4] -> array([-1,0,1])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nums=np.reshape(range(1,11), (2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 6  7  8  9 10]\n[ 7  8  9 10]\n[[ 2  4  6  8 10]\n [12 14 16 18 20]]\n[[ 1  2  4  4  5]\n [ 6  7  9  9 10]]\n"
    }
   ],
   "source": [
    "\n",
    "# Print second row of nums\n",
    "print(nums[1,:])\n",
    "\n",
    "# Print all elements of nums that are greater than six\n",
    "print(nums[nums > 6])\n",
    "\n",
    "# Double every element of nums\n",
    "nums_dbl = nums * 2\n",
    "print(nums_dbl)\n",
    "\n",
    "# Replace the third column of nums\n",
    "nums[:,2] = nums[:,2] + 1\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[10, 20, 30, 40, 50]\n"
    }
   ],
   "source": [
    "# Use range() to create a list of arrival times (10 through 50 incremented by 10). Create the list arrival_times by unpacking the range object.\n",
    "# Create a list of arrival times\n",
    "arrival_times = [*range(10, 51, 10)]\n",
    "\n",
    "print(arrival_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 7 17 27 37 47]\n"
    }
   ],
   "source": [
    "# Create a list of arrival times\n",
    "arrival_times = [*range(10,60,10)]\n",
    "\n",
    "# Convert arrival_times to an array and update the times\n",
    "arrival_times_np = np.array(arrival_times)\n",
    "new_times = arrival_times_np - 3\n",
    "\n",
    "print(new_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Jerry', 7), ('Kramer', 17), ('Elaine', 27), ('George', 37), ('Newman', 47)]\n"
    }
   ],
   "source": [
    "# Create a list of arrival times\n",
    "arrival_times = [*range(10,60,10)]\n",
    "\n",
    "# Convert arrival_times to an array and update the times\n",
    "arrival_times_np = np.array(arrival_times)\n",
    "new_times = arrival_times_np - 3\n",
    "\n",
    "# Use list comprehension and enumerate to pair guests to new times\n",
    "guest_arrivals = [(names[i],time) for i,time in enumerate(new_times)]\n",
    "\n",
    "print(guest_arrivals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welcome_guest(guest_arrival):\n",
    "    name,time=guest_arrival\n",
    "    return (f\"Welcome to Festivus {name}... You're {time} min late.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Welcome to Festivus Jerry... You're 7 min late.\nWelcome to Festivus Kramer... You're 17 min late.\nWelcome to Festivus Elaine... You're 27 min late.\nWelcome to Festivus George... You're 37 min late.\nWelcome to Festivus Newman... You're 47 min late.\n"
    }
   ],
   "source": [
    "# Create a list of arrival times\n",
    "arrival_times = [*range(10,60,10)]\n",
    "\n",
    "# Convert arrival_times to an array and update the times\n",
    "arrival_times_np = np.array(arrival_times)\n",
    "new_times = arrival_times_np - 3\n",
    "\n",
    "# Use list comprehension and enumerate to pair guests to new times\n",
    "guest_arrivals = [(names[i],time) for i,time in enumerate(new_times)]\n",
    "\n",
    "# Map the welcome_guest function to each (guest,time) pair\n",
    "welcome_map = map(welcome_guest, guest_arrivals)\n",
    "\n",
    "guest_welcomes = [*welcome_map]\n",
    "print(*guest_welcomes, sep='\\n')"
   ]
  },
  {
   "source": [
    "## Chapter 2:Timing and profiling code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.34 µs ± 175 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n566 ns ± 6.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
    }
   ],
   "source": [
    "# Create a list of integers (0-50) using list comprehension\n",
    "%timeit nums_list_comp = [num for num in range(51)]\n",
    "\n",
    "\n",
    "# Create a list of integers (0-50) by unpacking range\n",
    "%timeit nums_unpack = [*range(51)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "name  Gender Eye color               Race        Hair color  \\\nX1                                                                            \n0             A-Bomb    Male    yellow              Human           No Hair   \n1         Abe Sapien    Male      blue      Icthyo Sapien           No Hair   \n2           Abin Sur    Male      blue            Ungaran           No Hair   \n3        Abomination    Male     green  Human / Radiation           No Hair   \n4            Abraxas    Male      blue      Cosmic Entity             Black   \n..               ...     ...       ...                ...               ...   \n729  Yellowjacket II  Female      blue              Human  Strawberry Blond   \n730             Ymir    Male     white        Frost Giant           No Hair   \n731             Yoda    Male     brown     Yoda's species             White   \n732          Zatanna  Female      blue              Human             Black   \n733             Zoom    Male       red                  -             Brown   \n\n     Height          Publisher Skin color Alignment  Weight  \nX1                                                           \n0     203.0      Marvel Comics          -      good   441.0  \n1     191.0  Dark Horse Comics       blue      good    65.0  \n2     185.0          DC Comics        red      good    90.0  \n3     203.0      Marvel Comics          -       bad   441.0  \n4       NaN      Marvel Comics          -       bad     NaN  \n..      ...                ...        ...       ...     ...  \n729   165.0      Marvel Comics          -      good    52.0  \n730   304.8      Marvel Comics      white      good     NaN  \n731    66.0       George Lucas      green      good    17.0  \n732   170.0          DC Comics          -      good    57.0  \n733   185.0          DC Comics          -       bad    81.0  \n\n[734 rows x 10 columns]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('../datasets/heroes.csv', index_col=0)\n",
    "print(df)\n",
    "wts=np.array(df['Weight'])\n",
    "hts=np.array(df['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heroes=np.array(df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "47.1 µs ± 2.79 µs per loop (mean ± std. dev. of 5 runs, 25 loops each)\n"
    }
   ],
   "source": [
    "# Question: What is the correct syntax when using %timeit and only using 5 runs with 25 loops per each run?\n",
    "%timeit -r5 -n25 set(heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[]\n[]\n<class 'list'>\n<class 'list'>\n"
    }
   ],
   "source": [
    "# Create a list using the formal name\n",
    "formal_list = list()\n",
    "print(formal_list)\n",
    "\n",
    "# Create a list using the literal syntax\n",
    "literal_list = []\n",
    "print(literal_list)\n",
    "\n",
    "# Print out the type of formal_list\n",
    "print(type(formal_list))\n",
    "\n",
    "# Print out the type of literal_list\n",
    "print(type(literal_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "105 ns ± 0.969 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n22.6 ns ± 2.04 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
    }
   ],
   "source": [
    "%timeit formal_list = list()\n",
    "%timeit literal_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "330 µs ± 5.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
    }
   ],
   "source": [
    "%%timeit \n",
    "hero_wts_lbs = []\n",
    "for wt in wts:\n",
    "    hero_wts_lbs.append(wt * 2.20462)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.5 µs ± 76.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
    }
   ],
   "source": [
    "%%timeit\n",
    "wts_np = np.array(wts)\n",
    "hero_wts_lbs_np = wts_np * 2.20462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units(heroes, heights, weights):\n",
    "\n",
    "    new_hts = [ht * 0.39370  for ht in heights]\n",
    "    new_wts = [wt * 2.20462  for wt in weights]\n",
    "\n",
    "    hero_data = {}\n",
    "\n",
    "    for i,hero in enumerate(heroes):\n",
    "        hero_data[hero] = (new_hts[i], new_wts[i])\n",
    "\n",
    "    return hero_data"
   ]
  },
  {
   "source": [
    "* Question:\n",
    "What are the necessary steps you need to take in order to profile the convert_units() function acting on your superheroes data if you'd like to see line-by-line runtimes?\n",
    "* Answer:\n",
    "    * Use %load_ext line_profiler to load the line_profiler within your IPython session.\n",
    "    * Use %lprun -f convert_units convert_units(heroes, hts, wts) to get line-by-line runtimes.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* Question: What percentage of time is spent on the new_hts list comprehension line of code relative to the total amount of time spent in the convert_units() function?\n",
    "* Answer: 11% - 20%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* Q: What percentage of time is spent on the new_hts array broadcasting line of code relative to the total amount of time spent in the convert_units_broadcast() function?\n",
    "* A: 0% - 10%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* Question: What are the necessary steps you need to take in order to profile the convert_units() function acting on your superheroes data if you'd like to see the line-by-line memory consumption of convert_units()?\n",
    "* Answer: \n",
    "    * Use the command from hero_funcs import convert_units to load the function you'd like to profile.\n",
    "    * Use %load_ext memory_profiler to load the memory_profiler within your IPython session.\n",
    "    * Use %mprun -f convert_units convert_units(heroes, hts, wts) to get line-by-line memory allocations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmi_lists import *"
   ]
  },
  {
   "source": [
    "* Question: How much memory do the list comprehension lines of code consume in the calc_bmi_lists() function? (i.e., what is the total sum of the Increment column for these four lines of code?)\n",
    "* Answer: After above code running, Increment column value = 0.1 MiB\n",
    "* Note: In exercise pre-notes: A random sample of 25,000 superheroes has been loaded into your session as an array called sample_indices. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[167 236  74 ... 318 230 114]\n"
    }
   ],
   "source": [
    "sample_indices= np.random.randint(0,479,25000)\n",
    "print(sample_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "stream",
     "text": "Filename: d:\\çalışma\\ml_days\\ML_Python101\\datacamp\\python_programming\\bmi_lists.py\n\nLine #    Mem usage    Increment   Line Contents\n================================================\n     1    116.2 MiB    116.2 MiB   def calc_bmi_lists(sample_indices, hts, wts):\n     2                             \n     3                                 # Gather sample heights and weights as lists\n     4    116.2 MiB      0.0 MiB       s_hts = [hts[i] for i in sample_indices]\n     5    116.2 MiB      0.0 MiB       s_wts = [wts[i] for i in sample_indices]\n     6                             \n     7                                 # Convert heights from cm to m and square with list comprehension\n     8    116.3 MiB      0.1 MiB       s_hts_m_sqr = [(ht / 100) ** 2 for ht in s_hts]\n     9                             \n    10                                 # Calculate BMIs as a list with list comprehension\n    11    116.7 MiB      0.1 MiB       bmis = [s_wts[i] / s_hts_m_sqr[i] for i in range(len(sample_indices))]\n    12    116.7 MiB      0.0 MiB       return bmis"
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -f calc_bmi_lists calc_bmi_lists(sample_indices, hts, wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmi_arrays import calc_bmi_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "stream",
     "text": "Filename: d:\\çalışma\\ml_days\\ML_Python101\\datacamp\\python_programming\\bmi_arrays.py\n\nLine #    Mem usage    Increment   Line Contents\n================================================\n     1    116.2 MiB    116.2 MiB   def calc_bmi_arrays(sample_indices, hts, wts):\n     2                                 \n     3                                 # Gather sample heights and weights as arrays\n     4    116.2 MiB      0.0 MiB       s_hts = hts[sample_indices]\n     5    116.2 MiB      0.0 MiB       s_wts = wts[sample_indices]\n     6                             \n     7                                 # Convert heights from cm to m and square with broadcasting\n     8    116.2 MiB      0.0 MiB       s_hts_m_sqr = (s_hts / 100) ** 2\n     9                             \n    10                                 # Calculate BMIs as an array using broadcasting\n    11    116.2 MiB      0.0 MiB       bmis = s_wts / s_hts_m_sqr\n    12                             \n    13    116.2 MiB      0.0 MiB       return bmis"
    }
   ],
   "source": [
    "%reload_ext memory_profiler\n",
    "%mprun -f calc_bmi_arrays calc_bmi_arrays(sample_indices, hts, wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from publishers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['A-Bomb', 'Abomination', 'Abraxas', 'Absorbing Man', 'Agent 13', 'Agent Bob', 'Agent Zero', 'Air-Walker', 'Ajax', 'Ammo', 'Angel', 'Angel Dust', 'Angel Salvadore', 'Annihilus', 'Ant-Man', 'Ant-Man II', 'Anti-Venom', 'Apocalypse', 'Arachne', 'Archangel', 'Arclight', 'Ardina', 'Ares', 'Ariel', 'Armor', 'Atlas', 'Aurora', 'Azazel', 'Banshee', 'Bantam', 'Battlestar', 'Beak', 'Beast', 'Beetle', 'Beta Ray Bill', 'Beyonder', 'Big Man', 'Binary', 'Bird-Brain', 'Bird-Man', 'Bird-Man II', 'Bishop', 'Black Abbott', 'Black Bolt', 'Black Cat', 'Black Goliath', 'Black Knight III', 'Black Mamba', 'Black Panther', 'Black Widow', 'Black Widow II', 'Blackout', 'Blackwing', 'Blackwulf', 'Blade', 'Blaquesmith', 'Bling!', 'Blink', 'Blizzard', 'Blizzard', 'Blizzard II', 'Blob', 'Bloodaxe', 'Bloodhawk', 'Bloodwraith', 'Bolt', 'Boom-Boom', 'Boomer', 'Box', 'Box III', 'Box IV', 'Brother Voodoo', 'Bullseye', 'Bumbleboy', 'Cable', 'Callisto', 'Cannonball', 'Captain America', 'Captain Britain', 'Captain Mar-vell', 'Captain Marvel', 'Captain Planet', 'Captain Universe', 'Carnage', 'Cat', 'Cat II', 'Cecilia Reyes', 'Century', 'Cerebra', 'Chamber', 'Changeling', 'Clea', 'Cloak', 'Colossus', 'Copycat', 'Corsair', 'Cottonmouth', 'Crimson Crusader', 'Crimson Dynamo', 'Crystal', 'Cyclops', 'Cypher', 'Dagger', 'Daredevil', 'Darkhawk', 'Darkstar', 'Dazzler', 'Deadpool', 'Deathlok', 'Demogoblin', 'Destroyer', 'Diamondback', 'Doc Samson', 'Doctor Doom', 'Doctor Doom II', 'Doctor Octopus', 'Doctor Strange', 'Domino', 'Doppelganger', 'Dormammu', 'Drax the Destroyer', 'Ego', 'Electro', 'Elektra', 'Emma Frost', 'Evil Deadpool', 'Evilhawk', 'Exodus', 'Fabian Cortez', 'Falcon', 'Fallen One II', 'Feral', 'Fin Fang Foom', 'Firebird', 'Firelord', 'Firestar', 'Fixer', 'Forge', 'Franklin Richards', 'Franklin Storm', 'Frenzy', 'Frigga', 'Galactus', 'Gambit', 'Gamora', 'Genesis', 'Ghost Rider', 'Ghost Rider II', 'Giant-Man', 'Giant-Man II', 'Gladiator', 'Goblin Queen', 'Goliath', 'Goliath', 'Goliath', 'Goliath IV', 'Gravity', 'Green Goblin', 'Green Goblin II', 'Green Goblin III', 'Green Goblin IV', 'Groot', 'Guardian', 'Havok', 'Hawkeye', 'Hawkeye II', 'Hela', 'Hellcat', 'Hellstorm', 'Hercules', 'Hobgoblin', 'Hollow', 'Hope Summers', 'Howard the Duck', 'Hulk', 'Human Torch', 'Husk', 'Hybrid', 'Hydro-Man', 'Hyperion', 'Iceman', 'Ink', 'Invisible Woman', 'Iron Fist', 'Iron Man', 'Iron Monger', 'Jack of Hearts', 'Jean Grey', 'Jennifer Kale', 'Jessica Jones', 'Jigsaw', 'John Wraith', 'Jolt', 'Jubilee', 'Juggernaut', 'Junkpile', 'Justice', 'Kang', 'Kingpin', 'Klaw', 'Kraven II', 'Kraven the Hunter', 'Lady Bullseye', 'Lady Deathstrike', 'Leader', 'Leech', 'Legion', 'Living Brain', 'Living Tribunal', 'Lizard', 'Loki', 'Longshot', 'Luke Cage', 'Luna', 'Lyja', 'Mach-IV', 'Machine Man', 'Magneto', 'Magus', 'Man-Thing', 'Man-Wolf', 'Mandarin', 'Mantis', 'Marvel Girl', 'Maverick', 'Medusa', 'Meltdown', 'Mephisto', 'Meteorite', 'Mimic', 'Mister Fantastic', 'Mister Knife', 'Mister Sinister', 'Mockingbird', 'MODOK', 'Molten Man', 'Moon Knight', 'Moonstone', 'Morlun', 'Morph', 'Moses Magnum', 'Mr Immortal', 'Ms Marvel II', 'Multiple Man', 'Mysterio', 'Mystique', 'Namor', 'Namor', 'Namora', 'Namorita', 'Nebula', 'Negasonic Teenage Warhead', 'Nick Fury', 'Nightcrawler', 'Northstar', 'Nova', 'Nova', 'Odin', 'Omega Red', 'One-Above-All', 'Onslaught', 'Penance', 'Penance I', 'Penance II', 'Phoenix', 'Plantman', 'Polaris', 'Power Man', 'Professor X', 'Proto-Goblin', 'Psylocke', 'Punisher', 'Purple Man', 'Pyro', 'Quicksilver', 'Quill', 'Razor-Fist II', 'Red Hulk', 'Red Skull', 'Rhino', 'Ripcord', 'Rocket Raccoon', 'Rogue', 'Ronin', 'Sabretooth', 'Sage', 'Sandman', 'Sasquatch', 'Scarlet Spider', 'Scarlet Spider II', 'Scarlet Witch', 'Scorpia', 'Scorpion', 'Sebastian Shaw', 'Sentry', 'Shadow King', 'Shadowcat', 'Shang-Chi', 'Shatterstar', 'She-Hulk', 'She-Thing', 'Shocker', 'Shriek', 'Sif', 'Silk', 'Silver Surfer', 'Silverclaw', 'Siryn', 'Skaar', 'Snake-Eyes', 'Snowbird', 'Songbird', 'Speedball', 'Spider-Carnage', 'Spider-Girl', 'Spider-Gwen', 'Spider-Man', 'Spider-Man', 'Spider-Man', 'Spider-Woman', 'Spider-Woman II', 'Spider-Woman III', 'Spider-Woman IV', 'Spyke', 'Stacy X', 'Star-Lord', 'Stardust', 'Storm', 'Sunspot', 'Swarm', 'Synch', 'Taskmaster', 'Tempest', 'Thanos', 'Thing', 'Thor', 'Thor Girl', 'Thunderbird', 'Thunderbird II', 'Thunderbird III', 'Thunderstrike', 'Thundra', 'Tiger Shark', 'Tigra', 'Tinkerer', 'Toad', 'Toxin', 'Toxin', 'Triton', 'Ultragirl', 'Ultron', 'Utgard-Loki', 'Vagabond', 'Valkyrie', 'Vanisher', 'Venom', 'Venom II', 'Venom III', 'Venompool', 'Vertigo II', 'Vindicator', 'Vindicator', 'Vision', 'Vision II', 'Vulcan', 'Vulture', 'Walrus', 'War Machine', 'Warbird', 'Warlock', 'Warpath', 'Wasp', 'Watcher', 'Weapon XI', 'White Queen', 'Winter Soldier', 'Wiz Kid', 'Wolfsbane', 'Wolverine', 'Wonder Man', 'Wondra', 'Wyatt Wingfoot', 'X-23', 'X-Man', 'Yellow Claw', 'Yellowjacket', 'Yellowjacket II', 'Ymir']\n<class 'list'>\n['A-Bomb' 'Abomination' 'Abraxas' 'Absorbing Man' 'Agent 13' 'Agent Bob'\n 'Agent Zero' 'Air-Walker' 'Ajax' 'Ammo' 'Angel' 'Angel Dust'\n 'Angel Salvadore' 'Annihilus' 'Ant-Man' 'Ant-Man II' 'Anti-Venom'\n 'Apocalypse' 'Arachne' 'Archangel' 'Arclight' 'Ardina' 'Ares' 'Ariel'\n 'Armor' 'Atlas' 'Aurora' 'Azazel' 'Banshee' 'Bantam' 'Battlestar' 'Beak'\n 'Beast' 'Beetle' 'Beta Ray Bill' 'Beyonder' 'Big Man' 'Binary'\n 'Bird-Brain' 'Bird-Man' 'Bird-Man II' 'Bishop' 'Black Abbott'\n 'Black Bolt' 'Black Cat' 'Black Goliath' 'Black Knight III' 'Black Mamba'\n 'Black Panther' 'Black Widow' 'Black Widow II' 'Blackout' 'Blackwing'\n 'Blackwulf' 'Blade' 'Blaquesmith' 'Bling!' 'Blink' 'Blizzard' 'Blizzard'\n 'Blizzard II' 'Blob' 'Bloodaxe' 'Bloodhawk' 'Bloodwraith' 'Bolt'\n 'Boom-Boom' 'Boomer' 'Box' 'Box III' 'Box IV' 'Brother Voodoo' 'Bullseye'\n 'Bumbleboy' 'Cable' 'Callisto' 'Cannonball' 'Captain America'\n 'Captain Britain' 'Captain Mar-vell' 'Captain Marvel' 'Captain Planet'\n 'Captain Universe' 'Carnage' 'Cat' 'Cat II' 'Cecilia Reyes' 'Century'\n 'Cerebra' 'Chamber' 'Changeling' 'Clea' 'Cloak' 'Colossus' 'Copycat'\n 'Corsair' 'Cottonmouth' 'Crimson Crusader' 'Crimson Dynamo' 'Crystal'\n 'Cyclops' 'Cypher' 'Dagger' 'Daredevil' 'Darkhawk' 'Darkstar' 'Dazzler'\n 'Deadpool' 'Deathlok' 'Demogoblin' 'Destroyer' 'Diamondback' 'Doc Samson'\n 'Doctor Doom' 'Doctor Doom II' 'Doctor Octopus' 'Doctor Strange' 'Domino'\n 'Doppelganger' 'Dormammu' 'Drax the Destroyer' 'Ego' 'Electro' 'Elektra'\n 'Emma Frost' 'Evil Deadpool' 'Evilhawk' 'Exodus' 'Fabian Cortez' 'Falcon'\n 'Fallen One II' 'Feral' 'Fin Fang Foom' 'Firebird' 'Firelord' 'Firestar'\n 'Fixer' 'Forge' 'Franklin Richards' 'Franklin Storm' 'Frenzy' 'Frigga'\n 'Galactus' 'Gambit' 'Gamora' 'Genesis' 'Ghost Rider' 'Ghost Rider II'\n 'Giant-Man' 'Giant-Man II' 'Gladiator' 'Goblin Queen' 'Goliath' 'Goliath'\n 'Goliath' 'Goliath IV' 'Gravity' 'Green Goblin' 'Green Goblin II'\n 'Green Goblin III' 'Green Goblin IV' 'Groot' 'Guardian' 'Havok' 'Hawkeye'\n 'Hawkeye II' 'Hela' 'Hellcat' 'Hellstorm' 'Hercules' 'Hobgoblin' 'Hollow'\n 'Hope Summers' 'Howard the Duck' 'Hulk' 'Human Torch' 'Husk' 'Hybrid'\n 'Hydro-Man' 'Hyperion' 'Iceman' 'Ink' 'Invisible Woman' 'Iron Fist'\n 'Iron Man' 'Iron Monger' 'Jack of Hearts' 'Jean Grey' 'Jennifer Kale'\n 'Jessica Jones' 'Jigsaw' 'John Wraith' 'Jolt' 'Jubilee' 'Juggernaut'\n 'Junkpile' 'Justice' 'Kang' 'Kingpin' 'Klaw' 'Kraven II'\n 'Kraven the Hunter' 'Lady Bullseye' 'Lady Deathstrike' 'Leader' 'Leech'\n 'Legion' 'Living Brain' 'Living Tribunal' 'Lizard' 'Loki' 'Longshot'\n 'Luke Cage' 'Luna' 'Lyja' 'Mach-IV' 'Machine Man' 'Magneto' 'Magus'\n 'Man-Thing' 'Man-Wolf' 'Mandarin' 'Mantis' 'Marvel Girl' 'Maverick'\n 'Medusa' 'Meltdown' 'Mephisto' 'Meteorite' 'Mimic' 'Mister Fantastic'\n 'Mister Knife' 'Mister Sinister' 'Mockingbird' 'MODOK' 'Molten Man'\n 'Moon Knight' 'Moonstone' 'Morlun' 'Morph' 'Moses Magnum' 'Mr Immortal'\n 'Ms Marvel II' 'Multiple Man' 'Mysterio' 'Mystique' 'Namor' 'Namor'\n 'Namora' 'Namorita' 'Nebula' 'Negasonic Teenage Warhead' 'Nick Fury'\n 'Nightcrawler' 'Northstar' 'Nova' 'Nova' 'Odin' 'Omega Red'\n 'One-Above-All' 'Onslaught' 'Penance' 'Penance I' 'Penance II' 'Phoenix'\n 'Plantman' 'Polaris' 'Power Man' 'Professor X' 'Proto-Goblin' 'Psylocke'\n 'Punisher' 'Purple Man' 'Pyro' 'Quicksilver' 'Quill' 'Razor-Fist II'\n 'Red Hulk' 'Red Skull' 'Rhino' 'Ripcord' 'Rocket Raccoon' 'Rogue' 'Ronin'\n 'Sabretooth' 'Sage' 'Sandman' 'Sasquatch' 'Scarlet Spider'\n 'Scarlet Spider II' 'Scarlet Witch' 'Scorpia' 'Scorpion' 'Sebastian Shaw'\n 'Sentry' 'Shadow King' 'Shadowcat' 'Shang-Chi' 'Shatterstar' 'She-Hulk'\n 'She-Thing' 'Shocker' 'Shriek' 'Sif' 'Silk' 'Silver Surfer' 'Silverclaw'\n 'Siryn' 'Skaar' 'Snake-Eyes' 'Snowbird' 'Songbird' 'Speedball'\n 'Spider-Carnage' 'Spider-Girl' 'Spider-Gwen' 'Spider-Man' 'Spider-Man'\n 'Spider-Man' 'Spider-Woman' 'Spider-Woman II' 'Spider-Woman III'\n 'Spider-Woman IV' 'Spyke' 'Stacy X' 'Star-Lord' 'Stardust' 'Storm'\n 'Sunspot' 'Swarm' 'Synch' 'Taskmaster' 'Tempest' 'Thanos' 'Thing' 'Thor'\n 'Thor Girl' 'Thunderbird' 'Thunderbird II' 'Thunderbird III'\n 'Thunderstrike' 'Thundra' 'Tiger Shark' 'Tigra' 'Tinkerer' 'Toad' 'Toxin'\n 'Toxin' 'Triton' 'Ultragirl' 'Ultron' 'Utgard-Loki' 'Vagabond' 'Valkyrie'\n 'Vanisher' 'Venom' 'Venom II' 'Venom III' 'Venompool' 'Vertigo II'\n 'Vindicator' 'Vindicator' 'Vision' 'Vision II' 'Vulcan' 'Vulture'\n 'Walrus' 'War Machine' 'Warbird' 'Warlock' 'Warpath' 'Wasp' 'Watcher'\n 'Weapon XI' 'White Queen' 'Winter Soldier' 'Wiz Kid' 'Wolfsbane'\n 'Wolverine' 'Wonder Man' 'Wondra' 'Wyatt Wingfoot' 'X-23' 'X-Man'\n 'Yellow Claw' 'Yellowjacket' 'Yellowjacket II' 'Ymir']\n<class 'numpy.ndarray'>\n"
    }
   ],
   "source": [
    "publishers= list(df['Publisher'])\n",
    "desired_publisher=publishers[publishers==['George Lucas']]\n",
    "# Use get_publisher_heroes() to gather Star Wars heroes\n",
    "star_wars_heroes = get_publisher_heroes(heroes, publishers, desired_publisher)\n",
    "\n",
    "print(star_wars_heroes)\n",
    "print(type(star_wars_heroes))\n",
    "\n",
    "# Use get_publisher_heroes_np() to gather Star Wars heroes\n",
    "star_wars_heroes_np = get_publisher_heroes_np(heroes, publishers, desired_publisher)\n",
    "\n",
    "print(star_wars_heroes_np)\n",
    "print(type(star_wars_heroes_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The memory_profiler extension is already loaded. To reload it, use:\n  %reload_ext memory_profiler\n\n"
    },
    {
     "output_type": "stream",
     "text": "Filename: d:\\çalışma\\ml_days\\ML_Python101\\datacamp\\python_programming\\publishers.py\n\nLine #    Mem usage    Increment   Line Contents\n================================================\n     2    116.2 MiB    116.2 MiB   def get_publisher_heroes(heroes, publishers, desired_publisher):\n     3                                 \n     4    116.2 MiB      0.0 MiB       desired_heroes = []\n     5                             \n     6    116.2 MiB      0.0 MiB       for i,pub in enumerate(publishers):\n     7    116.2 MiB      0.0 MiB           if pub == desired_publisher:\n     8    116.2 MiB      0.0 MiB               desired_heroes.append(heroes[i])\n     9                             \n    10    116.2 MiB      0.0 MiB       return desired_heroes"
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%mprun -f get_publisher_heroes get_publisher_heroes(heroes, publishers, desired_publisher)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The memory_profiler extension is already loaded. To reload it, use:\n  %reload_ext memory_profiler\n\n"
    },
    {
     "output_type": "stream",
     "text": "Filename: d:\\çalışma\\ml_days\\ML_Python101\\datacamp\\python_programming\\publishers.py\n\nLine #    Mem usage    Increment   Line Contents\n================================================\n    12    116.2 MiB    116.2 MiB   def get_publisher_heroes_np(heroes, publishers, desired_publisher):\n    13                             \n    14    116.2 MiB      0.0 MiB       heroes_np = np.array(heroes)\n    15    116.2 MiB      0.0 MiB       pubs_np = np.array(publishers)\n    16                             \n    17    116.2 MiB      0.0 MiB       desired_heroes = heroes_np[pubs_np == desired_publisher]\n    18                             \n    19    116.2 MiB      0.0 MiB       return desired_heroes"
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%mprun -f get_publisher_heroes_np get_publisher_heroes_np(heroes, publishers, desired_publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np function has less time and equal memory usage. so prefer np"
   ]
  },
  {
   "source": [
    "## Chapter 3: Gaining efficiencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['abilities', 'against_bug', 'against_dark', 'against_dragon',\n       'against_electric', 'against_fairy', 'against_fight', 'against_fire',\n       'against_flying', 'against_ghost', 'against_grass', 'against_ground',\n       'against_ice', 'against_normal', 'against_poison', 'against_psychic',\n       'against_rock', 'against_steel', 'against_water', 'attack',\n       'base_egg_steps', 'base_happiness', 'base_total', 'capture_rate',\n       'classfication', 'defense', 'experience_growth', 'height_m', 'hp',\n       'japanese_name', 'name', 'percentage_male', 'pokedex_number',\n       'sp_attack', 'sp_defense', 'speed', 'type1', 'type2', 'weight_kg',\n       'generation', 'is_legendary'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "pokeman_data=pd.read_csv('../datasets/pokemon.csv')\n",
    "print(pokeman_data.columns)\n",
    "names=list(pokeman_data['name'])\n",
    "primary_types=list(pokeman_data['type1'])\n",
    "secondary_types=list(pokeman_data['type2'])\n",
    "generations=list(pokeman_data['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('Bulbasaur', 'grass')\n('Ivysaur', 'grass')\n('Venusaur', 'grass')\n('Charmander', 'fire')\n('Charmeleon', 'fire')\n"
    }
   ],
   "source": [
    "# Combine names and primary_types\n",
    "names_type1 = [*zip(names, primary_types)]\n",
    "\n",
    "print(*names_type1[:5], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('Bulbasaur', 'grass', 'poison')\n('Ivysaur', 'grass', 'poison')\n('Venusaur', 'grass', 'poison')\n('Charmander', 'fire', nan)\n('Charmeleon', 'fire', nan)\n"
    }
   ],
   "source": [
    "# Combine all three lists together\n",
    "names_types = [*zip(names, primary_types, secondary_types)]\n",
    "\n",
    "print(*names_types[:5], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('Bulbasaur', 'grass')\n('Ivysaur', 'grass')\n('Venusaur', 'grass')\n"
    }
   ],
   "source": [
    "# Combine five items from names and three items from primary_types\n",
    "differing_lengths = [*zip(names[0:5], primary_types[:3])]\n",
    "\n",
    "print(*differing_lengths, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({'water': 114, 'normal': 105, 'grass': 78, 'bug': 72, 'psychic': 53, 'fire': 52, 'rock': 45, 'electric': 39, 'poison': 32, 'ground': 32, 'dark': 29, 'fighting': 28, 'ghost': 27, 'dragon': 27, 'steel': 24, 'ice': 23, 'fairy': 18, 'flying': 3}) \n\nCounter({5: 156, 1: 151, 3: 135, 4: 107, 2: 100, 7: 80, 6: 72}) \n\nCounter({'S': 111, 'M': 66, 'C': 63, 'P': 55, 'G': 51, 'T': 49, 'D': 46, 'B': 44, 'L': 38, 'A': 34, 'H': 29, 'R': 28, 'F': 27, 'K': 26, 'V': 23, 'W': 23, 'E': 21, 'N': 18, 'Z': 10, 'J': 8, 'O': 8, 'I': 6, 'Y': 5, 'U': 5, 'Q': 4, 'X': 3})\n"
    }
   ],
   "source": [
    "\n",
    "# Collect the count of primary types\n",
    "type_count = Counter(primary_types)\n",
    "print(type_count, '\\n')\n",
    "\n",
    "# Collect the count of generations\n",
    "gen_count = Counter(generations)\n",
    "print(gen_count, '\\n')\n",
    "\n",
    "# Use list comprehension to get each Pokémon's starting letter\n",
    "starting_letters = [name[0] for name in names]\n",
    "\n",
    "# Collect the count of Pokémon for each starting_letter\n",
    "starting_letters_count = Counter(starting_letters)\n",
    "print(starting_letters_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon= ['Geodude', 'Cubone', 'Lickitung', 'Persian', 'Diglett']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'itertools.combinations'> \n\n[('Geodude', 'Cubone'), ('Geodude', 'Lickitung'), ('Geodude', 'Persian'), ('Geodude', 'Diglett'), ('Cubone', 'Lickitung'), ('Cubone', 'Persian'), ('Cubone', 'Diglett'), ('Lickitung', 'Persian'), ('Lickitung', 'Diglett'), ('Persian', 'Diglett')] \n\n[('Geodude', 'Cubone', 'Lickitung', 'Persian'), ('Geodude', 'Cubone', 'Lickitung', 'Diglett'), ('Geodude', 'Cubone', 'Persian', 'Diglett'), ('Geodude', 'Lickitung', 'Persian', 'Diglett'), ('Cubone', 'Lickitung', 'Persian', 'Diglett')]\n"
    }
   ],
   "source": [
    "# Import combinations from itertools\n",
    "from itertools import combinations\n",
    "\n",
    "# Create a combination object with pairs of Pokémon\n",
    "combos_obj = combinations(pokemon, 2)\n",
    "print(type(combos_obj), '\\n')\n",
    "\n",
    "# Convert combos_obj to a list by unpacking\n",
    "combos_2 = [*combos_obj]\n",
    "print(combos_2, '\\n')\n",
    "\n",
    "# Collect all possible combinations of 4 Pokémon directly into a list\n",
    "combos_4 = [*combinations(pokemon, 4)]\n",
    "print(combos_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2 comb:  10  4 comb: 5\n"
    }
   ],
   "source": [
    "print('2 comb: ', len(combos_2), ' 4 comb:', len(combos_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "ash_pokedex=['Pikachu', 'Bulbasaur', 'Koffing', 'Spearow', 'Vulpix', 'Wigglytuff', 'Zubat', 'Rattata', 'Psyduck', 'Squirtle']\n",
    "misty_pokedex=['Krabby', 'Horsea', 'Slowbro', 'Tentacool', 'Vaporeon', 'Magikarp', 'Poliwag', 'Starmie', 'Psyduck', 'Squirtle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'Squirtle', 'Psyduck'}\n{'Rattata', 'Pikachu', 'Koffing', 'Spearow', 'Bulbasaur', 'Vulpix', 'Zubat', 'Wigglytuff'}\n{'Poliwag', 'Tentacool', 'Starmie', 'Rattata', 'Krabby', 'Pikachu', 'Vaporeon', 'Horsea', 'Slowbro', 'Koffing', 'Spearow', 'Bulbasaur', 'Vulpix', 'Zubat', 'Wigglytuff', 'Magikarp'}\n"
    }
   ],
   "source": [
    "# Convert both lists to sets\n",
    "ash_set = set(ash_pokedex)\n",
    "misty_set = set(misty_pokedex)\n",
    "\n",
    "# Find the Pokémon that exist in both sets\n",
    "both = ash_set.intersection(misty_set)\n",
    "print(both)\n",
    "\n",
    "# Find the Pokémon that Ash has, and Misty does not have\n",
    "ash_only = ash_set.difference(misty_set)\n",
    "print(ash_only)\n",
    "\n",
    "# Find the Pokémon that are in only one set (not both)\n",
    "unique_to_set = ash_set.symmetric_difference(misty_set)\n",
    "print(unique_to_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "brock_pokedex=['Onix', 'Geodude', 'Zubat', 'Golem', 'Vulpix', 'Tauros', 'Kabutops', 'Omastar', 'Machop', 'Dugtrio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Onix', 'Geodude', 'Zubat', 'Golem', 'Vulpix', 'Tauros', 'Kabutops', 'Omastar', 'Machop', 'Dugtrio']\n{'Geodude', 'Omastar', 'Tauros', 'Machop', 'Dugtrio', 'Kabutops', 'Vulpix', 'Zubat', 'Golem', 'Onix'}\n"
    }
   ],
   "source": [
    "print(brock_pokedex)\n",
    "# Convert Brock's Pokédex to a set\n",
    "brock_pokedex_set = set(brock_pokedex)\n",
    "print(brock_pokedex_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nFalse\n"
    }
   ],
   "source": [
    "# Check if Psyduck is in Ash's list and Brock's set\n",
    "print('Psyduck' in ash_pokedex)\n",
    "print('Psyduck' in brock_pokedex_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\nTrue\n"
    }
   ],
   "source": [
    "# Check if Machop is in Ash's list and Brock's set\n",
    "print('Machop' in ash_pokedex)\n",
    "print('Machop' in brock_pokedex_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "227 ns ± 51.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n48.6 ns ± 1.58 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n222 ns ± 6.33 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n52.2 ns ± 4.34 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
    }
   ],
   "source": [
    "%timeit 'Psyduck' in ash_pokedex\n",
    "%timeit 'Psyduck' in brock_pokedex_set\n",
    "%timeit 'Machop' in ash_pokedex\n",
    "%timeit 'Machop' in brock_pokedex_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_items(data):\n",
    "    uniques = []\n",
    "\n",
    "    for item in data:\n",
    "        if item not in uniques:\n",
    "            uniques.append(item)\n",
    "\n",
    "    return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "801\n"
    }
   ],
   "source": [
    "# Use the provided function to collect unique Pokémon names\n",
    "uniq_names_func = find_unique_items(names)\n",
    "print(len(uniq_names_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "801\nTrue\n"
    }
   ],
   "source": [
    "# Convert the names list to a set to collect unique Pokémon names\n",
    "uniq_names_set = set(names)\n",
    "print(len(uniq_names_set))\n",
    "\n",
    "# Check that both unique collections are equivalent\n",
    "print(sorted(uniq_names_func) == sorted(uniq_names_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5.9 ms ± 39.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n25.2 µs ± 1.62 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Using a set to collect unique values is faster.'"
     },
     "metadata": {},
     "execution_count": 320
    }
   ],
   "source": [
    "%timeit find_unique_items(names)\n",
    "%timeit set(names)\n",
    "\"\"\"Using a set to collect unique values is faster.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'normal', 'fairy', 'bug', 'fire', 'ice', 'water', 'poison', 'psychic', 'dark', 'electric', 'ground', 'rock', 'flying', 'ghost', 'dragon', 'fighting', 'grass', 'steel'}\n{1, 2, 3, 4, 5, 6, 7}\n"
    }
   ],
   "source": [
    "# Use the best approach to collect unique primary types and generations\n",
    "uniq_types = set(primary_types) \n",
    "uniq_gens = set(generations)\n",
    "print(uniq_types, uniq_gens, sep='\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[]\n[('Bulbasaur', 9), ('Ivysaur', 7), ('Venusaur', 8), ('Charmander', 10), ('Charmeleon', 10)]\n"
    }
   ],
   "source": [
    "poke_names, poke_gens= names, generations\n",
    "gen1_gen2_name_lengths_loop = []\n",
    "\n",
    "# Collect Pokémon that belong to generation 1 or generation 2\n",
    "gen1_gen2_pokemon = [name for name,gen in zip(poke_names, poke_gens) if gen < 3]\n",
    "\n",
    "# Create a map object that gen1_gen2_pokemon the name lengths\n",
    "name_lengths_map = map(len, gen1_gen2_pokemon)\n",
    "\n",
    "# Combine gen1_gen2_pokemon and name_lengths_map into a list\n",
    "gen1_gen2_name_lengths = [*zip(gen1_gen2_pokemon, name_lengths_map)]\n",
    "\n",
    "print(gen1_gen2_name_lengths_loop[:5])\n",
    "print(gen1_gen2_name_lengths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['abilities', 'against_bug', 'against_dark', 'against_dragon',\n       'against_electric', 'against_fairy', 'against_fight', 'against_fire',\n       'against_flying', 'against_ghost', 'against_grass', 'against_ground',\n       'against_ice', 'against_normal', 'against_poison', 'against_psychic',\n       'against_rock', 'against_steel', 'against_water', 'attack',\n       'base_egg_steps', 'base_happiness', 'base_total', 'capture_rate',\n       'classfication', 'defense', 'experience_growth', 'height_m', 'hp',\n       'japanese_name', 'name', 'percentage_male', 'pokedex_number',\n       'sp_attack', 'sp_defense', 'speed', 'type1', 'type2', 'weight_kg',\n       'generation', 'is_legendary'],\n      dtype='object') \n                                              0\nabilities          ['Overgrow', 'Chlorophyll']\nagainst_bug                                  1\nagainst_dark                                 1\nagainst_dragon                               1\nagainst_electric                           0.5\nagainst_fairy                              0.5\nagainst_fight                              0.5\nagainst_fire                                 2\nagainst_flying                               2\nagainst_ghost                                1\nagainst_grass                             0.25\nagainst_ground                               1\nagainst_ice                                  2\nagainst_normal                               1\nagainst_poison                               1\nagainst_psychic                              2\nagainst_rock                                 1\nagainst_steel                                1\nagainst_water                              0.5\nattack                                      49\nbase_egg_steps                            5120\nbase_happiness                              70\nbase_total                                 318\ncapture_rate                                45\nclassfication                     Seed Pokémon\ndefense                                     49\nexperience_growth                      1059860\nheight_m                                   0.7\nhp                                          45\njapanese_name                 Fushigidaneフシギダネ\nname                                 Bulbasaur\npercentage_male                           88.1\npokedex_number                               1\nsp_attack                                   65\nsp_defense                                  65\nspeed                                       45\ntype1                                    grass\ntype2                                   poison\nweight_kg                                  6.9\ngeneration                                   1\nis_legendary                                 0\n"
    }
   ],
   "source": [
    "#(HP, Attack, Defense, Special Attack, Special Defense, and Speed respectively.)\n",
    "print(pokeman_data.columns, '\\n', pokeman_data.head(1).T)\n",
    "stats= np.array(pokeman_data[['hp', 'attack', 'defense', 'sp_attack', 'sp_defense', 'speed']])\n",
    "poke_list= list((pokeman_data[['name', 'base_total', 'base_happiness']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False \n\n[('Bulbasaur', 318, 53.0), ('Ivysaur', 405, 67.5), ('Venusaur', 625, 104.16666666666667)]\n['name', 'base_total', 'base_happiness'] \n\n3 strongest Pokémon:\n[('Mewtwo', 780, 130.0), ('Rayquaza', 780, 130.0), ('Kyogre', 770, 128.33333333333334)]\n"
    }
   ],
   "source": [
    "# Create a total stats array\n",
    "total_stats_np = stats.sum(axis=1)\n",
    "\n",
    "# Create an average stats array\n",
    "avg_stats_np = stats.mean(axis=1)\n",
    "\n",
    "# Combine names, total_stats_np, and avg_stats_np into a list\n",
    "poke_list_np = [*zip(names, total_stats_np, avg_stats_np)]\n",
    "\n",
    "print(poke_list_np == poke_list, '\\n')\n",
    "print(poke_list_np[:3])\n",
    "print(poke_list[:3], '\\n')\n",
    "top_3 = sorted(poke_list_np, key=lambda x: x[1], reverse=True)[:3]\n",
    "print('3 strongest Pokémon:\\n{}'.format(top_3))"
   ]
  },
  {
   "source": [
    "Writing better loops"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "generation 1: count = 151 percentage = 18.85\ngeneration 2: count = 100 percentage = 12.48\ngeneration 3: count = 135 percentage = 16.85\ngeneration 4: count = 107 percentage = 13.36\ngeneration 5: count = 156 percentage = 19.48\ngeneration 6: count =  72 percentage = 8.99\ngeneration 7: count =  80 percentage = 9.99\n"
    }
   ],
   "source": [
    "# Import Counter\n",
    "from collections import Counter \n",
    "\n",
    "# Collect the count of each generation\n",
    "gen_counts = Counter(generations)\n",
    "\n",
    "# Improve for loop by moving one calculation above the loop\n",
    "\n",
    "\n",
    "for gen,count in gen_counts.items():\n",
    "    total_count = len(generations)\n",
    "    gen_percent = round(count / total_count * 100, 2)\n",
    "    print('generation {}: count = {:3} percentage = {}'\n",
    "          .format(gen, count, gen_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_types=list(set(primary_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1, 'normal', 'fairy'], [2, 'normal', 'bug'], [3, 'normal', 'fire'], [4, 'normal', 'ice'], [5, 'normal', 'water'], [6, 'normal', 'poison'], [7, 'normal', 'psychic'], [8, 'normal', 'dark'], [9, 'normal', 'electric'], [10, 'normal', 'ground'], [11, 'normal', 'rock'], [12, 'normal', 'flying'], [13, 'normal', 'ghost'], [14, 'normal', 'dragon'], [15, 'normal', 'fighting'], [16, 'normal', 'grass'], [17, 'normal', 'steel'], [18, 'fairy', 'bug'], [19, 'fairy', 'fire'], [20, 'fairy', 'ice'], [21, 'fairy', 'water'], [22, 'fairy', 'poison'], [23, 'fairy', 'psychic'], [24, 'fairy', 'dark'], [25, 'fairy', 'electric'], [26, 'fairy', 'ground'], [27, 'fairy', 'rock'], [28, 'fairy', 'flying'], [29, 'fairy', 'ghost'], [30, 'fairy', 'dragon'], [31, 'fairy', 'fighting'], [32, 'fairy', 'grass'], [33, 'fairy', 'steel'], [34, 'bug', 'fire'], [35, 'bug', 'ice'], [36, 'bug', 'water'], [37, 'bug', 'poison'], [38, 'bug', 'psychic'], [39, 'bug', 'dark'], [40, 'bug', 'electric'], [41, 'bug', 'ground'], [42, 'bug', 'rock'], [43, 'bug', 'flying'], [44, 'bug', 'ghost'], [45, 'bug', 'dragon'], [46, 'bug', 'fighting'], [47, 'bug', 'grass'], [48, 'bug', 'steel'], [49, 'fire', 'ice'], [50, 'fire', 'water'], [51, 'fire', 'poison'], [52, 'fire', 'psychic'], [53, 'fire', 'dark'], [54, 'fire', 'electric'], [55, 'fire', 'ground'], [56, 'fire', 'rock'], [57, 'fire', 'flying'], [58, 'fire', 'ghost'], [59, 'fire', 'dragon'], [60, 'fire', 'fighting'], [61, 'fire', 'grass'], [62, 'fire', 'steel'], [63, 'ice', 'water'], [64, 'ice', 'poison'], [65, 'ice', 'psychic'], [66, 'ice', 'dark'], [67, 'ice', 'electric'], [68, 'ice', 'ground'], [69, 'ice', 'rock'], [70, 'ice', 'flying'], [71, 'ice', 'ghost'], [72, 'ice', 'dragon'], [73, 'ice', 'fighting'], [74, 'ice', 'grass'], [75, 'ice', 'steel'], [76, 'water', 'poison'], [77, 'water', 'psychic'], [78, 'water', 'dark'], [79, 'water', 'electric'], [80, 'water', 'ground'], [81, 'water', 'rock'], [82, 'water', 'flying'], [83, 'water', 'ghost'], [84, 'water', 'dragon'], [85, 'water', 'fighting'], [86, 'water', 'grass'], [87, 'water', 'steel'], [88, 'poison', 'psychic'], [89, 'poison', 'dark'], [90, 'poison', 'electric'], [91, 'poison', 'ground'], [92, 'poison', 'rock'], [93, 'poison', 'flying'], [94, 'poison', 'ghost'], [95, 'poison', 'dragon'], [96, 'poison', 'fighting'], [97, 'poison', 'grass'], [98, 'poison', 'steel'], [99, 'psychic', 'dark'], [100, 'psychic', 'electric'], [101, 'psychic', 'ground'], [102, 'psychic', 'rock'], [103, 'psychic', 'flying'], [104, 'psychic', 'ghost'], [105, 'psychic', 'dragon'], [106, 'psychic', 'fighting'], [107, 'psychic', 'grass'], [108, 'psychic', 'steel'], [109, 'dark', 'electric'], [110, 'dark', 'ground'], [111, 'dark', 'rock'], [112, 'dark', 'flying'], [113, 'dark', 'ghost'], [114, 'dark', 'dragon'], [115, 'dark', 'fighting'], [116, 'dark', 'grass'], [117, 'dark', 'steel'], [118, 'electric', 'ground'], [119, 'electric', 'rock'], [120, 'electric', 'flying'], [121, 'electric', 'ghost'], [122, 'electric', 'dragon'], [123, 'electric', 'fighting'], [124, 'electric', 'grass'], [125, 'electric', 'steel'], [126, 'ground', 'rock'], [127, 'ground', 'flying'], [128, 'ground', 'ghost'], [129, 'ground', 'dragon'], [130, 'ground', 'fighting'], [131, 'ground', 'grass'], [132, 'ground', 'steel'], [133, 'rock', 'flying'], [134, 'rock', 'ghost'], [135, 'rock', 'dragon'], [136, 'rock', 'fighting'], [137, 'rock', 'grass'], [138, 'rock', 'steel'], [139, 'flying', 'ghost'], [140, 'flying', 'dragon'], [141, 'flying', 'fighting'], [142, 'flying', 'grass'], [143, 'flying', 'steel'], [144, 'ghost', 'dragon'], [145, 'ghost', 'fighting'], [146, 'ghost', 'grass'], [147, 'ghost', 'steel'], [148, 'dragon', 'fighting'], [149, 'dragon', 'grass'], [150, 'dragon', 'steel'], [151, 'fighting', 'grass'], [152, 'fighting', 'steel'], [153, 'grass', 'steel']]\n"
    }
   ],
   "source": [
    "\n",
    "# Collect all possible pairs using combinations()\n",
    "possible_pairs = [*combinations(pokemon_types, 2)]\n",
    "\n",
    "# Create an empty list called enumerated_tuples\n",
    "enumerated_tuples = []\n",
    "\n",
    "# Add a line to append each enumerated_pair_tuple to the empty list above\n",
    "for i,pair in enumerate(possible_pairs, 1):\n",
    "    enumerated_pair_tuple = (i,) + pair\n",
    "    enumerated_tuples.append(enumerated_pair_tuple)\n",
    "\n",
    "# Convert all tuples in enumerated_tuples to a list\n",
    "enumerated_pairs = [*map(list, enumerated_tuples)]\n",
    "print(enumerated_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "68.95880149812734\n('Bulbasaur', 45, -0.9020830044724206)\n('Ivysaur', 60, -0.3373116377517634)\n('Venusaur', 80, 0.4157168512091129)\n"
    }
   ],
   "source": [
    "hps=stats[:,0]\n",
    "# Calculate the total HP avg and total HP standard deviation\n",
    "hp_avg = np.mean(hps)\n",
    "hp_std = np.std(hps)\n",
    "print(hp_avg)\n",
    "# Use NumPy to eliminate the previous for loop\n",
    "z_scores = (hps - hp_avg)/hp_std\n",
    "\n",
    "# Combine names, hps, and z_scores\n",
    "poke_zscores2 = [*zip(names, hps, z_scores)]\n",
    "print(*poke_zscores2[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "237 µs ± 14.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
    }
   ],
   "source": [
    "# Use list comprehension with the same logic as the highest_hp_pokemon code block\n",
    "%timeit highest_hp_pokemon2 = [(name, hp, z_score) for name, hp, z_score in poke_zscores2 if z_score > 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('Wigglytuff', 140, 2.674802318091742)\n('Chansey', 250, 6.816459007376562)\n('Lapras', 130, 2.2982880736113036)\n('Vaporeon', 130, 2.2982880736113036)\n('Snorlax', 160, 3.4278308070526182)\n('Lanturn', 125, 2.1100309513710847)\n('Wobbuffet', 190, 4.557373540493932)\n('Blissey', 255, 7.004716129616781)\n('Slaking', 150, 3.05131656257218)\n('Hariyama', 144, 2.825408015883917)\n('Wailmer', 130, 2.2982880736113036)\n('Wailord', 170, 3.8043450515330566)\n('Drifblim', 150, 3.05131656257218)\n('Munchlax', 135, 2.486545195851523)\n('Giratina', 150, 3.05131656257218)\n('Alomomola', 165, 3.616087929292837)\n('Kyurem', 125, 2.1100309513710847)\n('Gogoat', 123, 2.034728102474997)\n('Aurorus', 123, 2.034728102474997)\n('Xerneas', 126, 2.1476823758191284)\n('Yveltal', 126, 2.1476823758191284)\n('Zygarde', 216, 5.536310576143072)\n('Solgaleo', 137, 2.5618480447476104)\n('Lunala', 137, 2.5618480447476104)\n('Guzzlord', 223, 5.799870547279379)\n"
    }
   ],
   "source": [
    "print(*highest_hp_pokemon2, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "37 ms ± 557 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
    }
   ],
   "source": [
    "%%timeit\n",
    "poke_zscores = []\n",
    "\n",
    "for name,hp in zip(names, hps):\n",
    "    hp_avg = hps.mean()\n",
    "    hp_std = hps.std()\n",
    "    z_score = (hp - hp_avg)/hp_std\n",
    "    poke_zscores.append((name, hp, z_score))\n",
    "highest_hp_pokemon = []\n",
    "\n",
    "for name,hp,zscore in poke_zscores:\n",
    "    if zscore > 2:\n",
    "        highest_hp_pokemon.append((name, hp, zscore))"
   ]
  },
  {
   "source": [
    "## Chapter 4: Basic pandas optimizations\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseball_df=pd.read_csv('../datasets/baseball_stats.csv')\n",
    "pit_df=baseball_df[(baseball_df['Team']=='PIT') & (baseball_df['Year'] >2007)& (baseball_df['Year'] <2013)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21\nTeam              PIT\nLeague             NL\nYear             2012\nRS                651\nRA                674\nW                  79\nOBP             0.304\nSLG             0.395\nBA              0.243\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 162\nOOBP            0.314\nOSLG             0.39\nName: 21, dtype: object\n<class 'pandas.core.series.Series'>\n51\nTeam              PIT\nLeague             NL\nYear             2011\nRS                610\nRA                712\nW                  72\nOBP             0.309\nSLG             0.368\nBA              0.244\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 162\nOOBP            0.338\nOSLG            0.409\nName: 51, dtype: object\n<class 'pandas.core.series.Series'>\n81\nTeam              PIT\nLeague             NL\nYear             2010\nRS                587\nRA                866\nW                  57\nOBP             0.304\nSLG             0.373\nBA              0.242\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 162\nOOBP            0.348\nOSLG            0.449\nName: 81, dtype: object\n<class 'pandas.core.series.Series'>\n111\nTeam              PIT\nLeague             NL\nYear             2009\nRS                636\nRA                768\nW                  62\nOBP             0.318\nSLG             0.387\nBA              0.252\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 161\nOOBP            0.346\nOSLG            0.442\nName: 111, dtype: object\n<class 'pandas.core.series.Series'>\n141\nTeam              PIT\nLeague             NL\nYear             2008\nRS                735\nRA                884\nW                  67\nOBP              0.32\nSLG             0.403\nBA              0.258\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 162\nOOBP            0.362\nOSLG            0.454\nName: 141, dtype: object\n<class 'pandas.core.series.Series'>\n"
    }
   ],
   "source": [
    "# Iterate over pit_df and print each row\n",
    "for i,row in pit_df.iterrows():\n",
    "    print(i)\n",
    "    print(row)\n",
    "    print(type(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(21, Team              PIT\nLeague             NL\nYear             2012\nRS                651\nRA                674\nW                  79\nOBP             0.304\nSLG             0.395\nBA              0.243\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 162\nOOBP            0.314\nOSLG             0.39\nName: 21, dtype: object)\n<class 'tuple'>\n(51, Team              PIT\nLeague             NL\nYear             2011\nRS                610\nRA                712\nW                  72\nOBP             0.309\nSLG             0.368\nBA              0.244\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 162\nOOBP            0.338\nOSLG            0.409\nName: 51, dtype: object)\n<class 'tuple'>\n(81, Team              PIT\nLeague             NL\nYear             2010\nRS                587\nRA                866\nW                  57\nOBP             0.304\nSLG             0.373\nBA              0.242\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 162\nOOBP            0.348\nOSLG            0.449\nName: 81, dtype: object)\n<class 'tuple'>\n(111, Team              PIT\nLeague             NL\nYear             2009\nRS                636\nRA                768\nW                  62\nOBP             0.318\nSLG             0.387\nBA              0.252\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 161\nOOBP            0.346\nOSLG            0.442\nName: 111, dtype: object)\n<class 'tuple'>\n(141, Team              PIT\nLeague             NL\nYear             2008\nRS                735\nRA                884\nW                  67\nOBP              0.32\nSLG             0.403\nBA              0.258\nPlayoffs            0\nRankSeason        NaN\nRankPlayoffs      NaN\nG                 162\nOOBP            0.362\nOSLG            0.454\nName: 141, dtype: object)\n<class 'tuple'>\n"
    }
   ],
   "source": [
    "# Print the row and type of each row\n",
    "for row_tuple in pit_df.iterrows():\n",
    "    print(row_tuple)\n",
    "    print(type(row_tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  \\\n24   SFG     NL  2012  718  649  94  0.327  0.397  0.269         1   \n54   SFG     NL  2011  570  578  86  0.303  0.368  0.242         0   \n84   SFG     NL  2010  697  583  92  0.321  0.408  0.257         1   \n114  SFG     NL  2009  657  611  88  0.309  0.389  0.257         0   \n144  SFG     NL  2008  640  759  72  0.321  0.382  0.262         0   \n\n     RankSeason  RankPlayoffs    G   OOBP   OSLG  \n24          4.0           1.0  162  0.313  0.393  \n54          NaN           NaN  162  0.309  0.346  \n84          5.0           1.0  162  0.313  0.370  \n114         NaN           NaN  162  0.314  0.372  \n144         NaN           NaN  162  0.341  0.404  \n"
    }
   ],
   "source": [
    "giants_df=baseball_df[(baseball_df['Team']=='SFG') & (baseball_df['Year'] >2007)& (baseball_df['Year'] <2013)]\n",
    "print(giants_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_run_diff(runs_scored, runs_allowed):\n",
    "\n",
    "    run_diff = runs_scored - runs_allowed\n",
    "\n",
    "    return run_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  \\\n24   SFG     NL  2012  718  649  94  0.327  0.397  0.269         1   \n54   SFG     NL  2011  570  578  86  0.303  0.368  0.242         0   \n84   SFG     NL  2010  697  583  92  0.321  0.408  0.257         1   \n114  SFG     NL  2009  657  611  88  0.309  0.389  0.257         0   \n144  SFG     NL  2008  640  759  72  0.321  0.382  0.262         0   \n\n     RankSeason  RankPlayoffs    G   OOBP   OSLG   RD  \n24          4.0           1.0  162  0.313  0.393   69  \n54          NaN           NaN  162  0.309  0.346   -8  \n84          5.0           1.0  162  0.313  0.370  114  \n114         NaN           NaN  162  0.314  0.372   46  \n144         NaN           NaN  162  0.341  0.404 -119  \n"
    }
   ],
   "source": [
    "# Create an empty list to store run differentials\n",
    "run_diffs = []\n",
    "\n",
    "# Write a for loop and collect runs allowed and runs scored for each row\n",
    "for i,row in giants_df.iterrows():\n",
    "    runs_scored = row['RS']\n",
    "    runs_allowed = row['RA']\n",
    "    \n",
    "    # Use the provided function to calculate run_diff for each row\n",
    "    run_diff = calc_run_diff(runs_scored, runs_allowed)\n",
    "    \n",
    "    # Append each run differential to the output list\n",
    "    run_diffs.append(run_diff)\n",
    "\n",
    "giants_df['RD'] = run_diffs\n",
    "print(giants_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangers_df=baseball_df[(baseball_df['Team']=='TEX') ][['Team', 'League', 'Year', 'RS', 'RA', 'W', 'G',  'Playoffs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pandas(Index=27, Team='TEX', League='AL', Year=2012, RS=808, RA=707, W=93, G=162, Playoffs=1)\n27 2012 93\n27 2012 93\nPandas(Index=57, Team='TEX', League='AL', Year=2011, RS=855, RA=677, W=96, G=162, Playoffs=1)\n57 2011 96\n57 2011 96\nPandas(Index=87, Team='TEX', League='AL', Year=2010, RS=787, RA=687, W=90, G=162, Playoffs=1)\n87 2010 90\n87 2010 90\nPandas(Index=117, Team='TEX', League='AL', Year=2009, RS=784, RA=740, W=87, G=162, Playoffs=0)\n117 2009 87\nPandas(Index=147, Team='TEX', League='AL', Year=2008, RS=901, RA=967, W=79, G=162, Playoffs=0)\n147 2008 79\nPandas(Index=177, Team='TEX', League='AL', Year=2007, RS=816, RA=844, W=75, G=162, Playoffs=0)\n177 2007 75\nPandas(Index=207, Team='TEX', League='AL', Year=2006, RS=835, RA=784, W=80, G=162, Playoffs=0)\n207 2006 80\nPandas(Index=237, Team='TEX', League='AL', Year=2005, RS=865, RA=858, W=79, G=162, Playoffs=0)\n237 2005 79\nPandas(Index=268, Team='TEX', League='AL', Year=2004, RS=860, RA=794, W=89, G=162, Playoffs=0)\n268 2004 89\nPandas(Index=298, Team='TEX', League='AL', Year=2003, RS=826, RA=969, W=71, G=162, Playoffs=0)\n298 2003 71\nPandas(Index=328, Team='TEX', League='AL', Year=2002, RS=843, RA=882, W=72, G=162, Playoffs=0)\n328 2002 72\nPandas(Index=358, Team='TEX', League='AL', Year=2001, RS=890, RA=968, W=73, G=162, Playoffs=0)\n358 2001 73\nPandas(Index=388, Team='TEX', League='AL', Year=2000, RS=848, RA=974, W=71, G=162, Playoffs=0)\n388 2000 71\nPandas(Index=418, Team='TEX', League='AL', Year=1999, RS=945, RA=859, W=95, G=162, Playoffs=1)\n418 1999 95\n418 1999 95\nPandas(Index=448, Team='TEX', League='AL', Year=1998, RS=940, RA=871, W=88, G=162, Playoffs=1)\n448 1998 88\n448 1998 88\nPandas(Index=476, Team='TEX', League='AL', Year=1997, RS=807, RA=823, W=77, G=162, Playoffs=0)\n476 1997 77\nPandas(Index=504, Team='TEX', League='AL', Year=1996, RS=928, RA=799, W=90, G=163, Playoffs=1)\n504 1996 90\n504 1996 90\nPandas(Index=532, Team='TEX', League='AL', Year=1993, RS=835, RA=751, W=86, G=162, Playoffs=0)\n532 1993 86\nPandas(Index=558, Team='TEX', League='AL', Year=1992, RS=682, RA=753, W=77, G=162, Playoffs=0)\n558 1992 77\nPandas(Index=584, Team='TEX', League='AL', Year=1991, RS=829, RA=814, W=85, G=162, Playoffs=0)\n584 1991 85\nPandas(Index=610, Team='TEX', League='AL', Year=1990, RS=676, RA=696, W=83, G=162, Playoffs=0)\n610 1990 83\nPandas(Index=636, Team='TEX', League='AL', Year=1989, RS=695, RA=714, W=83, G=162, Playoffs=0)\n636 1989 83\nPandas(Index=662, Team='TEX', League='AL', Year=1988, RS=637, RA=735, W=70, G=161, Playoffs=0)\n662 1988 70\nPandas(Index=688, Team='TEX', League='AL', Year=1987, RS=823, RA=849, W=75, G=162, Playoffs=0)\n688 1987 75\nPandas(Index=714, Team='TEX', League='AL', Year=1986, RS=771, RA=743, W=87, G=162, Playoffs=0)\n714 1986 87\nPandas(Index=740, Team='TEX', League='AL', Year=1985, RS=617, RA=785, W=62, G=161, Playoffs=0)\n740 1985 62\nPandas(Index=766, Team='TEX', League='AL', Year=1984, RS=656, RA=714, W=69, G=161, Playoffs=0)\n766 1984 69\nPandas(Index=792, Team='TEX', League='AL', Year=1983, RS=639, RA=609, W=77, G=163, Playoffs=0)\n792 1983 77\nPandas(Index=818, Team='TEX', League='AL', Year=1982, RS=590, RA=749, W=64, G=162, Playoffs=0)\n818 1982 64\nPandas(Index=844, Team='TEX', League='AL', Year=1980, RS=756, RA=752, W=76, G=163, Playoffs=0)\n844 1980 76\nPandas(Index=870, Team='TEX', League='AL', Year=1979, RS=750, RA=698, W=83, G=162, Playoffs=0)\n870 1979 83\nPandas(Index=896, Team='TEX', League='AL', Year=1978, RS=692, RA=632, W=87, G=162, Playoffs=0)\n896 1978 87\nPandas(Index=922, Team='TEX', League='AL', Year=1977, RS=767, RA=657, W=94, G=162, Playoffs=0)\n922 1977 94\nPandas(Index=947, Team='TEX', League='AL', Year=1976, RS=616, RA=652, W=76, G=162, Playoffs=0)\n947 1976 76\nPandas(Index=971, Team='TEX', League='AL', Year=1975, RS=714, RA=733, W=79, G=162, Playoffs=0)\n971 1975 79\nPandas(Index=995, Team='TEX', League='AL', Year=1974, RS=690, RA=698, W=83, G=161, Playoffs=0)\n995 1974 83\nPandas(Index=1019, Team='TEX', League='AL', Year=1973, RS=619, RA=844, W=57, G=162, Playoffs=0)\n1019 1973 57\n"
    }
   ],
   "source": [
    "# Loop over the DataFrame and print each row\n",
    "for row in rangers_df.itertuples():\n",
    "  print(row)\n",
    "  i = row.Index\n",
    "  year = row.Year\n",
    "  wins = row.W\n",
    "  print(i, year, wins)\n",
    "    # Check if rangers made Playoffs (1 means yes; 0 means no)\n",
    "  if row.Playoffs == 1:\n",
    "    print(i, year, wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  \\\n26   TBR     AL  2012  697  577  90  0.317  0.394  0.240         0   \n56   TBR     AL  2011  707  614  91  0.322  0.402  0.244         1   \n86   TBR     AL  2010  802  649  96  0.333  0.403  0.247         1   \n116  TBR     AL  2009  803  754  84  0.343  0.439  0.263         0   \n146  TBR     AL  2008  774  671  97  0.340  0.422  0.260         1   \n\n     RankSeason  RankPlayoffs    G   OOBP   OSLG  \n26          NaN           NaN  162  0.294  0.352  \n56          6.0           4.0  162  0.303  0.383  \n86          2.0           4.0  162  0.308  0.404  \n116         NaN           NaN  162  0.324  0.417  \n146         2.0           2.0  162  0.314  0.400  \n"
    }
   ],
   "source": [
    "yankees_df=baseball_df[(baseball_df['Team']=='NYY') ][['Team', 'League', 'Year', 'RS', 'RA', 'W', 'G',  'Playoffs']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Team League  Year   RS   RA    W    G  Playoffs   RD\n18    NYY     AL  2012  804  668   95  162         1  136\n48    NYY     AL  2011  867  657   97  162         1  210\n78    NYY     AL  2010  859  693   95  162         1  166\n108   NYY     AL  2009  915  753  103  162         1  162\n138   NYY     AL  2008  789  727   89  162         0   62\n168   NYY     AL  2007  968  777   94  162         1  191\n198   NYY     AL  2006  930  767   97  162         1  163\n228   NYY     AL  2005  886  789   95  162         1   97\n259   NYY     AL  2004  897  808  101  162         1   89\n289   NYY     AL  2003  877  716  101  163         1  161\n319   NYY     AL  2002  897  697  103  161         1  200\n349   NYY     AL  2001  804  713   95  161         1   91\n379   NYY     AL  2000  871  814   87  161         1   57\n409   NYY     AL  1999  900  731   98  162         1  169\n439   NYY     AL  1998  965  656  114  162         1  309\n468   NYY     AL  1997  891  688   96  162         1  203\n496   NYY     AL  1996  871  787   92  162         1   84\n524   NYY     AL  1993  821  761   88  162         0   60\n550   NYY     AL  1992  733  746   76  162         0  -13\n576   NYY     AL  1991  674  777   71  162         0 -103\n602   NYY     AL  1990  603  749   67  162         0 -146\n628   NYY     AL  1989  698  792   74  161         0  -94\n654   NYY     AL  1988  772  748   85  161         0   24\n680   NYY     AL  1987  788  758   89  162         0   30\n706   NYY     AL  1986  797  738   90  162         0   59\n732   NYY     AL  1985  839  660   97  161         0  179\n758   NYY     AL  1984  758  679   87  162         0   79\n784   NYY     AL  1983  770  703   91  162         0   67\n810   NYY     AL  1982  709  716   79  162         0   -7\n836   NYY     AL  1980  820  662  103  162         1  158\n862   NYY     AL  1979  734  672   89  160         0   62\n888   NYY     AL  1978  735  582  100  163         1  153\n914   NYY     AL  1977  831  651  100  162         1  180\n940   NYY     AL  1976  730  575   97  159         1  155\n964   NYY     AL  1975  681  588   83  160         0   93\n988   NYY     AL  1974  671  623   89  162         0   48\n1012  NYY     AL  1973  641  610   80  162         0   31\n1036  NYY     AL  1971  648  641   81  162         0    7\n1060  NYY     AL  1970  680  612   93  163         0   68\n1083  NYY     AL  1969  562  587   80  162         0  -25\n1105  NYY     AL  1968  536  531   83  164         0    5\n1126  NYY     AL  1967  522  621   72  163         0  -99\n1146  NYY     AL  1966  611  612   70  160         0   -1\n1166  NYY     AL  1965  611  604   77  162         0    7\n1186  NYY     AL  1964  730  577   99  164         1  153\n1206  NYY     AL  1963  714  547  104  161         1  167\n1226  NYY     AL  1962  817  680   96  162         1  137\n"
    }
   ],
   "source": [
    "run_diffs = []\n",
    "\n",
    "# Loop over the DataFrame and calculate each row's run differential\n",
    "for row in yankees_df.itertuples():\n",
    "    \n",
    "    runs_scored = row.RS\n",
    "    runs_allowed = row.RA\n",
    "\n",
    "    run_diff = calc_run_diff(runs_scored, runs_allowed)\n",
    "    \n",
    "    run_diffs.append(run_diff)\n",
    "\n",
    "# Append new column\n",
    "yankees_df['RD'] = run_diffs\n",
    "print(yankees_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RS   RA   W  Playoffs\nYear                        \n2012  697  577  90         0\n2011  707  614  91         1\n2010  802  649  96         1\n2009  803  754  84         0\n2008  774  671  97         1\n"
    }
   ],
   "source": [
    "rays_df=baseball_df[(baseball_df['Team']=='TBR') ][['Year', 'RS', 'RA', 'W', 'Playoffs']].set_index('Year')\n",
    "print(rays_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Year\n2012    1364\n2011    1413\n2010    1548\n2009    1641\n2008    1543\ndtype: int64\n"
    }
   ],
   "source": [
    "# Gather sum of all columns\n",
    "stat_totals = rays_df.apply('sum', axis=1)\n",
    "print(stat_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Year\n2012    1274\n2011    1321\n2010    1451\n2009    1557\n2008    1445\ndtype: int64\n"
    }
   ],
   "source": [
    "# Gather total runs scored in all games per year\n",
    "total_runs_scored = rays_df[['RS', 'RA']].apply(sum, axis=1)\n",
    "print(total_runs_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_playoffs(num_playoffs): \n",
    "    if num_playoffs == 1:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Year\n2012     No\n2011    Yes\n2010    Yes\n2009     No\n2008    Yes\ndtype: object\n"
    }
   ],
   "source": [
    "# Convert numeric playoffs to text\n",
    "textual_playoffs = rays_df.apply(lambda row: text_playoffs(row['Playoffs']), axis=1)\n",
    "print(textual_playoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbacks_df=baseball_df[(baseball_df['Team']=='ARI') ][['Team', 'League', 'Year', 'RS', 'RA', 'W', 'G',  'Playoffs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Team League  Year   RS   RA   W    G  Playoffs\n0    ARI     NL  2012  734  688  81  162         0\n30   ARI     NL  2011  731  662  94  162         1\n60   ARI     NL  2010  713  836  65  162         0\n90   ARI     NL  2009  720  782  70  162         0\n120  ARI     NL  2008  720  706  82  162         0\n"
    }
   ],
   "source": [
    "\n",
    "# Display the first five rows of the DataFrame\n",
    "print(dbacks_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_win_perc(wins, games_played):\n",
    "    win_perc = wins / games_played\n",
    "    return np.round(win_perc,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Team League  Year   RS   RA   W    G  Playoffs\n0    ARI     NL  2012  734  688  81  162         0\n30   ARI     NL  2011  731  662  94  162         1\n60   ARI     NL  2010  713  836  65  162         0\n90   ARI     NL  2009  720  782  70  162         0\n120  ARI     NL  2008  720  706  82  162         0\n0      0.50\n30     0.58\n60     0.40\n90     0.43\n120    0.51\n150    0.56\n180    0.47\n210    0.48\n241    0.31\n271    0.52\n301    0.60\n331    0.57\n361    0.52\n391    0.62\n421    0.40\ndtype: float64 \n\n"
    }
   ],
   "source": [
    "# Display the first five rows of the DataFrame\n",
    "print(dbacks_df.head())\n",
    "\n",
    "# Create a win percentage Series \n",
    "win_percs = dbacks_df.apply(lambda row: calc_win_perc(row['W'], row['G']), axis=1)\n",
    "print(win_percs, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Team League  Year   RS   RA    W    G  Playoffs    WP\n0    ARI     NL  2012  734  688   81  162         0  0.50\n30   ARI     NL  2011  731  662   94  162         1  0.58\n60   ARI     NL  2010  713  836   65  162         0  0.40\n90   ARI     NL  2009  720  782   70  162         0  0.43\n120  ARI     NL  2008  720  706   82  162         0  0.51\n150  ARI     NL  2007  712  732   90  162         1  0.56\n180  ARI     NL  2006  773  788   76  162         0  0.47\n210  ARI     NL  2005  696  856   77  162         0  0.48\n241  ARI     NL  2004  615  899   51  162         0  0.31\n271  ARI     NL  2003  717  685   84  162         0  0.52\n301  ARI     NL  2002  819  674   98  162         1  0.60\n331  ARI     NL  2001  818  677   92  162         1  0.57\n361  ARI     NL  2000  792  754   85  162         0  0.52\n391  ARI     NL  1999  908  676  100  162         1  0.62\n421  ARI     NL  1998  665  812   65  162         0  0.40 \n\n    Team League  Year   RS   RA    W    G  Playoffs    WP\n0    ARI     NL  2012  734  688   81  162         0  0.50\n30   ARI     NL  2011  731  662   94  162         1  0.58\n120  ARI     NL  2008  720  706   82  162         0  0.51\n150  ARI     NL  2007  712  732   90  162         1  0.56\n271  ARI     NL  2003  717  685   84  162         0  0.52\n301  ARI     NL  2002  819  674   98  162         1  0.60\n331  ARI     NL  2001  818  677   92  162         1  0.57\n361  ARI     NL  2000  792  754   85  162         0  0.52\n391  ARI     NL  1999  908  676  100  162         1  0.62\n"
    }
   ],
   "source": [
    "# Append a new column to dbacks_df\n",
    "dbacks_df['WP'] = win_percs\n",
    "print(dbacks_df, '\\n')\n",
    "\n",
    "# Display dbacks_df where WP is greater than 0.50\n",
    "print(dbacks_df[dbacks_df['WP'] >= 0.50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_win_perc(wins, games_played):\n",
    "    win_perc = wins / games_played\n",
    "    return np.round(win_perc,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the W array and G array to calculate win percentages\n",
    "win_percs_np = calc_win_perc(baseball_df['W'].values, baseball_df['G'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n\n   RankPlayoffs    G   OOBP   OSLG    WP  \n0           NaN  162  0.317  0.415  0.50  \n1           5.0  162  0.306  0.378  0.58  \n2           4.0  162  0.315  0.403  0.57  \n3           NaN  162  0.331  0.428  0.43  \n4           NaN  162  0.335  0.424  0.38  \n"
    }
   ],
   "source": [
    "# Append a new column to baseball_df that stores all win percentages\n",
    "baseball_df['WP'] = win_percs_np\n",
    "\n",
    "print(baseball_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "223 ms ± 9.46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
    }
   ],
   "source": [
    "%%timeit\n",
    "win_percs_list = []\n",
    "\n",
    "for i in range(len(baseball_df)):\n",
    "    row = baseball_df.iloc[i]\n",
    "\n",
    "    wins = row['W']\n",
    "    games_played = row['G']\n",
    "\n",
    "    win_perc = calc_win_perc(wins, games_played)\n",
    "\n",
    "    win_percs_list.append(win_perc)\n",
    "\n",
    "baseball_df['WP'] = win_percs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "376 µs ± 14 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
    }
   ],
   "source": [
    "%%timeit\n",
    "win_percs_np = calc_win_perc(baseball_df['W'].values, baseball_df['G'].values)\n",
    "baseball_df['WP'] = win_percs_np"
   ]
  },
  {
   "source": [
    "The NumPy array approach is faster than the .iloc approach"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_win_perc(RS, RA):\n",
    "    prediction = RS ** 2 / (RS ** 2 + RA ** 2)\n",
    "    return np.round(prediction, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "18.8 ms ± 782 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
    }
   ],
   "source": [
    "%%timeit\n",
    "win_perc_preds_loop = []\n",
    "\n",
    "# Use a loop and .itertuples() to collect each row's predicted win percentage\n",
    "for baseball_tuple in baseball_df.itertuples():\n",
    "    runs_scored = baseball_tuple.RS\n",
    "    runs_allowed = baseball_tuple.RA\n",
    "    win_perc_pred = predict_win_perc(runs_scored, runs_allowed)\n",
    "    win_perc_preds_loop.append(win_perc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "51.6 ms ± 1.84 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
    }
   ],
   "source": [
    "%%timeit\n",
    "# Apply predict_win_perc to each row of the DataFrame\n",
    "win_perc_preds_apply = baseball_df.apply(lambda row: predict_win_perc(row['RS'], row['RA']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "412 µs ± 6.98 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
    }
   ],
   "source": [
    "%%timeit\n",
    "# Calculate the win percentage predictions using NumPy arrays\n",
    "win_perc_preds_np = predict_win_perc(baseball_df['RS'].values, baseball_df['RA'].values)\n",
    "baseball_df['WP_preds'] = win_perc_preds_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baseball_df.head())"
   ]
  }
 ]
}